@inproceedings{monti2011shifted,
address = {Sant Feliu de Gu\'{\i}xols},
author = {Monti, Gianna Serafina and Mateu-Figueras, Gl\`{o}ria and Pawlowsky-Glahn, Vera and Egozcue, Juan Jos\'{e}},
booktitle = {CoDaWork 2011, the 4th international Workshop on Compositional Data analysis},
editor = {Egozcue, J J and Tolosana-Delgado, R and Ortego, M I},
isbn = {978-84-87867-76-7},
keywords = {aitchison geometry,compositional data},
publisher = {CIMNE},
title = {{The shifted-scaled Dirichlet distribution in the simplex}},
url = {http://hdl.handle.net/10281/22158},
year = {2011}
}
@article{tian2003bayesian,
author = {Tian, Guo-Liang and Ng, Kai Wang and Geng, Zhi},
journal = {Statistica Sinica},
number = {1},
pages = {189--206},
publisher = {C/O DR HC HO, INST STATISTICAL SCIENCE, ACADEMIA SINICA, TAIPEI 115, TAIWAN},
title = {{Bayesian computation for contingency tables with incomplete cell-counts}},
volume = {13},
year = {2003}
}
@article{scott1971clustering,
abstract = {The standard classification model with several normal populations is extended to the cluster analysis situation where little or no previous information about the population parameters is available. Some common clustering procedures are shown to be extensions of likelihood ratio methods of classification. The analysis suggests that the procedures may have a tendency to partition the sample into groups of about the same size. This suggestion is examined in an example.},
author = {Scott, A.J. and Symons, M.J.},
issn = {0006341X},
journal = {Biometrics},
pages = {387--397},
title = {{Clustering methods based on likelihood ratio criteria}},
volume = {27},
year = {1971}
}
@article{rayens1994dependence,
abstract = {Compositional data arise naturally in several branches of science, including chemistry, geology, biology, medicine, ecology, and manufacturing design. Thus the correct statistical analysis of this type of data is of fundamental importance. Prior to the pioneering and extensive work of Aitchison, the Dirichlet distribution provided the parametric model of choice when analyzing such data. But Aitchison and others have since pointed out that the Dirichlet distribution is appropriate only for modeling compositional vectors that exhibit forms of extreme independence. Aitchison developed his logistic normal classes partly in response to this shortcoming. Unfortunately, Aitchison's logistic normal classes do not contain the Dirichlet distribution as a special case. As a result, they exhibit interesting dependence structures but are unable to model extreme independence. The generalized Liouville family is studied in this article. This family, which contains the Dirichlet class, is shown to contain densities that can model either complicated dependence or complicated independence structures.},
author = {Rayens, W S and Srinivasan, C},
doi = {10.2307/2291008},
isbn = {0162-1459},
issn = {01621459},
journal = {Journal of the American Statistical Association},
keywords = {CLOSURE,CODA,COMPOSITIONAL DATA,NEUTRALITY,SUB},
pages = {1465--1470},
title = {{Dependence properties of generalized Liouville distributions on the Simplex}},
url = {<Go to ISI>://A1994PU33000031},
volume = {89},
year = {1994}
}
@manual{R2014soft,
address = {Vienna, Austria},
author = {{R Core Team}},
organization = {R Foundation for Statistical Computing},
title = {{R: A Language and Environment for Statistical Computing}},
url = {http://www.r-project.org/},
year = {2014}
}
@article{pawlowsky2001geometric,
author = {Pawlowsky-Glahn, Vera and Egozcue, Juan Jos\'{e}},
doi = {10.1007/s004770100077},
issn = {1436-3240},
journal = {Stochastic Environmental Research and Risk Assessment},
keywords = {Euclidean space,Key words: Aitchison geometry,compositional data,finite dimensional Hilbert space,metric center,metric variance.},
language = {English},
number = {5},
pages = {384--398},
publisher = {Springer-Verlag},
title = {{Geometric approach to statistical analysis on the simplex}},
url = {http://dx.doi.org/10.1007/s004770100077},
volume = {15},
year = {2001}
}
@article{papageorgiou2001model,
author = {Papageorgiou, Ioulia and Baxter, M J and Cau, M A},
doi = {10.1111/1475-4754.00037},
issn = {1475-4754},
journal = {Archaeometry},
keywords = {CERAMIC COMPOSITIONS,CLASSIFICATION MAXIMUM-LIKELIHOOD,CLUSTER ANALYSIS,LEAD ISOTOPE DATA,MIXTURE MAXIMUM-LIKELIHOOD,OUTLIERS},
number = {4},
pages = {571--588},
publisher = {Blackwell Publishers Ltd},
title = {{Model-based Cluster Analysis of Artefact Compositional Data}},
url = {http://dx.doi.org/10.1111/1475-4754.00037},
volume = {43},
year = {2001}
}
@techreport{ongaro2008new,
abstract = {The Dirichlet family owes its privileged status within simplex distributions to easyness of interpretation and good mathematical properties. In particular, we recall fundamental properties for the analysis of compositional data such as closure under amalgamation and subcomposition. From a probabilistic point of view, it is characterised (uniquely) by a variety of independence relationships which makes it indisputably the reference model for expressing the non trivial idea of substantial independence for compositions. Indeed, its well known inadequacy as a general model for compositional data stems from such an independence structure together with the poorness of its parametrisation. In this paper a new class of distributions (called Flexible Dirichlet) capable of handling various dependence structures and containing the Dirichlet as a special case is presented. The new model exhibits a considerably richer parametrisation which, for example, allows to model the means and (part of) the variance-covariance matrix separately. Moreover, such a model preserves some good mathematical properties of the Dirichlet, i.e. closure under amalgamation and subcomposition with new parameters simply related to the parent composition parameters. Furthermore, the joint and conditional distributions of subcompositions and relative totals can be expressed as simple mixtures of two Flexible Dirichlet distributions. The basis generating the Flexible Dirichlet, though keeping compositional invariance, shows a dependence structure which allows various forms of partitional dependence to be contemplated by the model (e.g. non-neutrality, subcompositional dependence and subcompositional non-invariance), independence cases being identified by suitable parameter configurations. In particular, within this model substantial independence among subsets of components of the composition naturally occurs when the subsets have a Dirichlet distribution},
author = {Ongaro, Andrea and Migliorati, Sonia and Monti, Gianna Serafina},
file = {:home/marc/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ongaro, Migliorati, Monti - 2008 - A new distribution on the simplex containing the Dirichlet family.pdf:pdf},
institution = {Universitat de Girona. Departament d’Inform\`{a}tica i Matem\`{a}tica Aplicada},
keywords = {Dirichlet,Invari\`{a}ncia,Models matem\`{a}tics,Principi de},
language = {eng},
month = may,
title = {{A new distribution on the simplex containing the Dirichlet family}},
url = {http://dugi-doc.udg.edu//handle/10256/726},
year = {2008}
}
@book{ng2011dirichlet,
author = {Ng, Kai Wang and Tian, Guo-Liang and Tang, Man-Lai},
publisher = {John Wiley \& Sons},
title = {{Dirichlet and Related Distributions: Theory, Methods and Applications}},
volume = {888},
year = {2011}
}
@article{narayanan1991algorithm,
author = {Narayanan, A},
journal = {Applied Statistics},
pages = {365--374},
publisher = {JSTOR},
title = {{Algorithm AS 266: maximum likelihood estimation of the parameters of the Dirichlet distribution}},
year = {1991}
}
@book{mclachlan2000finite,
author = {McLachlan, Geoffrey J. and Peel, D},
publisher = {John Wiley \& Sons, New York},
title = {{Finite Mixture Models, Willey Series in Probability and Statistics}},
year = {2000}
}
@article{mateu2013normal,
abstract = {Phenomena with a constrained sample space appear frequently in practice. This is the case e.g. with strictly positive data and with compositional data, like percentages and the like. If the natural measure of difference is not the absolute one, it is possible to use simple algebraic properties to show that it is more convenient to work with a geometry that is not the usual Euclidean geometry in real space, and with a measure which is not the usual Lebesgue measure, leading to alternative models which better fit the phenomenon under study. The general approach is presented and illustrated both on the positive real line and on the D-part simplex.},
archivePrefix = {arXiv},
arxivId = {0802.2643},
author = {Mateu-Figueras, Gl\`{o}ria and Pawlowsky-Glahn, Vera and Egozcue, Juan Jos\'{e}},
eprint = {0802.2643},
journal = {SORT},
month = feb,
number = {1},
pages = {29--56},
title = {{The normal distribution in some constrained sample spaces}},
url = {http://arxiv.org/abs/0802.2643},
volume = {37},
year = {2013}
}
@incollection{Mateu-Figueras2011,
author = {Mateu-Figueras, Gl\`{o}ria and Pawlowsky-Glahn, Vera and Egozcue, Juan Jos\'{e}},
booktitle = {Compositional Data Analysis},
doi = {10.1002/9781119976462.ch3},
isbn = {9781119976462},
keywords = {Euclidean space structure of simplex - orthonormal,establishing role of coordinates - in the simplex,mathematical statistics, and real analysis - using,principle of working on coordinates - standard sta,role of coordinates in statistics - standard or cl,similar concepts - for addressing random compositi,simplex SD, a (D – 1)-dimensional subset - of D-di,standard statistical methodology - traditionally d,the simplex, notation used - standard in compositi,theory - statistical modeling, principle of workin},
pages = {29--42},
publisher = {John Wiley \& Sons, Ltd},
title = {{The Principle of Working on Coordinates}},
url = {http://dx.doi.org/10.1002/9781119976462.ch3},
year = {2011}
}
@article{mateu2007skew,
author = {Mateu-Figueras, Gl\`{o}ria and Pawlowsky-Glahn, Vera},
doi = {10.1080/03610920601126258},
journal = {Communications in Statistics - Theory and Methods},
number = {9},
pages = {1787--1802},
title = {{The Skew-Normal Distribution on the Simplex}},
url = {http://dx.doi.org/10.1080/03610920601126258},
volume = {36},
year = {2007}
}
@article{martin2012model,
address = {Amsterdam, The Netherlands, The Netherlands},
author = {Mart\'{\i}n-Fern\'{a}ndez, Josep A and Hron, K and Templ, M and Filzmoser, P and Palarea-Albaladejo, J},
doi = {10.1016/j.csda.2012.02.012},
issn = {0167-9473},
journal = {Comput. Stat. Data Anal.},
keywords = {Balances,EM algorithm,Log-ratio transformations,Robust regression,Values below detection limit},
number = {9},
pages = {2688--2704},
publisher = {Elsevier Science Publishers B. V.},
title = {{Model-based Replacement of Rounded Zeros in Compositional Data: Classical and Robust Approaches}},
url = {http://dx.doi.org/10.1016/j.csda.2012.02.012},
volume = {56},
year = {2012}
}
@article{mardia2007protein,
abstract = {A fundamental problem in bioinformatics is to characterize the secondary structure of a protein, which has traditionally been carried out by examining a scatterplot (Ramachandran plot) of the conformational angles. We examine two natural bivariate von Mises distributions--referred to as Sine and Cosine models--which have five parameters and, for concentrated data, tend to a bivariate normal distribution. These are analyzed and their main properties derived. Conditions on the parameters are established which result in bimodal behavior for the joint density and the marginal distribution, and we note an interesting situation in which the joint density is bimodal but the marginal distributions are unimodal. We carry out comparisons of the two models, and it is seen that the Cosine model may be preferred. Mixture distributions of the Cosine model are fitted to two representative protein datasets using the expectation maximization algorithm, which results in an objective partition of the scatterplot into a number of components. Our results are consistent with empirical observations; new insights are discussed.},
author = {Mardia, Kanti V. and Taylor, Charles C. and Subramaniam, Ganesh K.},
doi = {10.1111/j.1541-0420.2006.00682.x},
issn = {0006341X},
journal = {Biometrics},
keywords = {Bivariate angular data,Bivariate circular mixture,Directional statistics,Distribution on torus,Myoglobin,Protein conformational angles,Ramachandran plots},
pmid = {17688502},
title = {{Protein bioinformatics and mixtures of bivariate von Mises distributions for angular data}},
volume = {63},
year = {2007}
}
@article{lin2010robust,
author = {Lin, Tsung-I},
doi = {10.1007/s11222-009-9128-9},
issn = {0960-3174},
journal = {Statistics and Computing},
keywords = {MCEM-type algorithms,MSN,MST,Multivariate truncated normal,Multivariate truncated t,Outliers},
language = {English},
number = {3},
pages = {343--356},
publisher = {Springer US},
title = {{Robust mixture modeling using multivariate skew t distributions}},
url = {http://dx.doi.org/10.1007/s11222-009-9128-9},
volume = {20},
year = {2010}
}
@article{lee2013finite,
address = {Hingham, MA, USA},
author = {Lee, Sharon X. and McLachlan, Geoffrey J.},
doi = {10.1007/s11222-012-9362-4},
issn = {0960-3174},
journal = {Statistics and Computing},
keywords = {EM algorithm,Mixture models,Skew normal distributions,Skew t component distributions},
number = {2},
pages = {181--202},
publisher = {Kluwer Academic Publishers},
title = {{Finite Mixtures of Multivariate Skew T-distributions: Some Recent and New Results}},
url = {http://dx.doi.org/10.1007/s11222-012-9362-4},
volume = {24},
year = {2014}
}
@article{lee2011fitting,
abstract = {We show how the expectation-maximization (EM) algorithm can be applied exactly for the fitting of mixtures of general multivariate skew t (MST) distributions, eliminating the need for computationally expensive Monte Carlo estimation. Finite mixtures of MST distributions have proven to be useful in modelling heterogeneous data with asymmetric and heavy tail behaviour. Recently, they have been exploited as an effective tool for modelling flow cytometric data. However, without restrictions on the the characterizations of the component skew t-distributions, Monte Carlo methods have been used to fit these models. In this paper, we show how the EM algorithm can be implemented for the iterative computation of the maximum likelihood estimates of the model parameters without resorting to Monte Carlo methods for mixtures with unrestricted MST components. The fast calculation of semi-infinite integrals on the E-step of the EM algorithm is effected by noting that they can be put in the form of moments of the truncated multivariate t-distribution, which subsequently can be expressed in terms of the non-truncated form of the t-distribution function for which fast algorithms are available. We demonstrate the usefulness of the proposed methodology by some applications to three real data sets.},
archivePrefix = {arXiv},
arxivId = {1109.4706},
author = {Lee, Sharon X. and McLachlan, Geoffrey J.},
eprint = {1109.4706},
month = sep,
title = {{On the fitting of mixtures of multivariate skew t-distributions via the EM algorithm}},
url = {http://arxiv.org/abs/1109.4706},
year = {2011}
}
@article{hansen1982large,
abstract = {This paper studies estimators that make sample analogues of population orthogonality conditions close to zero. Strong consistency and asymptotic normality of such estimators is established under the assumption that the observable variables are stationary and ergodic. Since many linear and nonlinear econometric estimators reside within the class of estimators studied in this paper, a convenient summary of the large sample properties of these estimators, including some whose large sample properties have not heretofore been discussed, is provided.},
author = {Hansen, Lars Peter},
doi = {10.2307/1912775},
isbn = {00129682},
issn = {00129682},
journal = {Econometrica},
pages = {1029--1054},
pmid = {100},
title = {{Large sample properties of generalized method of moments estimators}},
url = {http://www.jstor.org/stable/1912775},
volume = {50},
year = {1982}
}
@article{fraley2002model,
abstract = {Cluster analysis is the automated search for groups of related observations in a dataset. Most clustering done in practice is based largely on heuristic but intuitively reasonable procedures, and most clustering methods available in commercial software are also of this type. However, there is little systematic guidance associated with these methods for solving important practical questions that arise in cluster analysis, such as how many clusters are there, which clustering method should be used, and how should outliers be handled. We review a general methodology for model-based clustering that provides a principled statistical approach to these issues. We also show that this can be useful for other problems in multivariate analysis, such as discriminant analysis and multivariate density estimation. We give examples from medical diagnosis, minefield detection, cluster recovery from noisy data, and spatial density estimation. Finally, we mention limitations of the methodology and discuss recent developments in model-based clustering for non-Gaussian data, high-dimensional datasets, large datasets, and Bayesian estimation. CR - Copyright \&\#169; 2002 American Statistical Association},
author = {Fraley, Chris and Raftery, Adrian E.},
doi = {10.1198/016214502760047131},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
pages = {611--631},
pmid = {20815477},
title = {{Model-Based Clustering, Discriminant Analysis, and Density Estimation}},
volume = {97},
year = {2002}
}
@article{egozcue2005balances,
abstract = {Amalgamation of parts of a composition has been extensively used as a technique of analysis to achieve reduced dimension, as was discussed during the CoDaWork'03 meeting (Girona, Spain, 2003). It was shown to be a non-linear operation in the simplex that does not preserve distances under perturbation. The discussion motivated the introduction in the present paper of concepts such as group of parts, balance between groups, and sequential binary partition, which are intended to provide tools of compositional data analysis for dimension reduction. Key concepts underlying this development are the established tools of subcomposition, coordinates in an orthogonal basis of the simplex, balancing element and, in general, the Aitchison geometry in the simplex. Main new results are: a method to analyze grouped parts of a compositional vector through the adequate coordinates in an ad hoc orthonormal basis; and the study of balances of groups of parts (inter-group analysis) as an orthogonal projection similar to that used in standard subcompositional analysis (intra-group analysis). A simulated example compares results when testing equal centers of two populations using amalgamated parts and balances; it shows that, in certain circumstances, results from both analysis can disagree.},
author = {Egozcue, Juan Jos\'{e} and Pawlowsky-Glahn, Vera},
doi = {10.1007/s11004-005-7381-9},
isbn = {0882-8121},
issn = {08828121},
journal = {Mathematical Geology},
keywords = {Amalgamation,Euclidean geometry,Log-ratio analysis,Orthogonal projection,Simplex,Subcomposition},
pages = {795--828},
title = {{Groups of parts and their balances in compositional data analysis}},
volume = {37},
year = {2005}
}
@article{egozcue2003isometric,
abstract = {Geometry in the simplex has been developed in the last 15 years mainly based on the contributions due to J. Aitchison. The main goal was to develop analytical tools for the statistical analysis of compositional data. Our present aim is to get a further insight into some aspects of this geometry in order to clarify the way for more complex statistical approaches. This is done by way of orthonormal bases, which allow for a straightforward handling of geometric elements in the simplex. The transformation into real coordinates preserves all metric properties and is thus called isometric logratio transformation (ilr). An important result is the decomposition of the simplex, as a vector space, into orthogonal subspaces associated with nonoverlapping subcompositions. This gives the key to join compositions with different parts into a single composition by using a balancing element. The relationship between ilr transformations and the centered-logratio (clr) and additive-logratio (alr) transformations is also studied. Exponential growth or decay of mass is used to illustrate compositional linear processes, parallelism and orthogonality in the simplex.},
author = {Egozcue, Juan Jos\'{e} and Pawlowsky-Glahn, Vera and Mateu-Figueras, Gl\`{o}ria and Barcel\'{o}-Vidal, Carles},
doi = {10.1023/A:1023818214614},
isbn = {0882-8121},
issn = {08828121},
journal = {Mathematical Geology},
keywords = {Aitchison distance,Aitchison geometry,Geodesic,Orthogonal subcompositions,Ternary diagram},
pages = {279--300},
title = {{Isometric Logratio Transformations for Compositional Data Analysis}},
volume = {35},
year = {2003}
}
@article{connor1969concepts,
abstract = {Concepts of independence for nonnegative continuous random variables, X1,⋯, Xk, subject to the constraint $\Sigma$ Xi = 1 are developed. These concepts provide a means of modeling random vectors of proportions which is useful in analyzing certain kinds of data; and which may be of interest in quantifying prior opinions about multinomial parameters. A generalization of the Dirichlet distribution is given, and its relation to the Dirichlet is simply indicated by means of the concepts. The concepts are used to obtain conclusions of biological interest for data on bone composition in rats and scute growth in turtles.},
author = {Connor, Robert J and Mosimann, James E},
doi = {10.1080/01621459.1969.10500963},
isbn = {01621459},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
pages = {194--206},
title = {{Concepts of Independence for Proportions with a Generalization of the Dirichlet Distribution}},
url = {http://www.jstor.org/stable/2283728},
volume = {64},
year = {1969}
}
@article{celeux1992classification,
abstract = {Setting the optimization-based clustering methods under the classification maximum likelihood approach, we define and study a general Classification EM algorithm. Then, we derive from this algorithm two stochastic algorithms, incorporating random perturbations, to reduce the initial-position dependence of the classical optimization clustering algorithms. Numerical experiments, reported for the variance criterion, show that both stochastic algorithms perform well compared with the standard k-means algorithm which is a particular version of the Classification EM algorithm.},
author = {Celeux, Gilles and Govaert, G\'{e}rard},
doi = {10.1016/0167-9473(92)90042-E},
isbn = {0167-9473},
issn = {01679473},
journal = {Computational Statistics \& Data Analysis},
number = {3},
pages = {315--332},
title = {{A classification EM algorithm for clustering and two stochastic versions}},
volume = {14},
year = {1992}
}
@inbook{buccianti2011natural,
author = {Buccianti, Antonella},
booktitle = {Compositional Data Analysis},
doi = {10.1002/9781119976462.ch18},
isbn = {9781119976462},
keywords = {adding independent random variables - asymptotica,and uncertainty,central limit theorem,cycles of elements,from volcanic discharges,geochemical processes and log-r,governing distribution of elements in geochemistr,investigating geochemical behaviour - of elements,log-ratio approach and,natural laws,using log-ratios},
pages = {255--266},
publisher = {John Wiley \& Sons, Ltd},
title = {{Natural Laws Governing the Distribution of the Elements in Geochemistry: The Role of the Log-Ratio Approach}},
url = {http://dx.doi.org/10.1002/9781119976462.ch18},
year = {2011}
}
@article{browne2013mixture,
abstract = {We introduce a mixture of generalized hyperbolic distributions as an alternative to the ubiquitous mixture of Gaussian distributions as well as their near relatives of which the mixture of multivariate t and skew-t distributions are predominant. The mathematical development of our mixture of generalized hyperbolic distributions model relies on its relationship with the generalized inverse Gaussian distribution. The latter is reviewed before our mixture models are presented along with details of the aforesaid reliance. Parameter estimation is outlined within the expectation-maximization framework before the performance of our mixture models is illustrated in clustering applications on simulated and real data. In particular, the ability of our models to recover parameters for data from underlying Gaussian, and skew-t distributions is demonstrated. Finally, the role of Generalized hyperbolic mixtures within the wider model-based clustering, classification, and density estimation literature is discussed.},
archivePrefix = {arXiv},
arxivId = {1305.1036},
author = {Browne, Ryan P. and McNicholas, Paul D.},
eprint = {1305.1036},
month = may,
title = {{A Mixture of Generalized Hyperbolic Distributions}},
url = {http://arxiv.org/abs/1305.1036},
year = {2013}
}
@article{bouveyron2014model,
abstract = {Model-based clustering is a popular tool which is renowned for its probabilistic foundations and its flexibility. However, high-dimensional data are nowadays more and more frequent and, unfortunately, classical model-based clustering techniques show a disappointing behavior in high-dimensional spaces. This is mainly due to the fact that model-based clustering methods are dramatically over-parametrized in this case. However, high-dimensional spaces have specific characteristics which are useful for clustering and recent techniques exploit those characteristics. After having recalled the bases of model-based clustering, dimension reduction approaches, regularization-based techniques, parsimonious modeling, subspace clustering methods and clustering methods based on variable selection are reviewed. Existing softwares for model-based clustering of high-dimensional data will be also reviewed and their practical use will be illustrated on real-world data sets.},
author = {Bouveyron, Charles and Brunet-Saumard, Camille},
doi = {10.1016/j.csda.2012.12.008},
isbn = {01679473},
issn = {01679473},
journal = {Computational Statistics \& Data Analysis},
keywords = {Dimension reduction,High-dimensional data,Model-based clustering,Parsimonious models,R package,Regularization,Software,Subspace clustering,Variable selection},
pages = {52--78},
title = {{Model-based clustering of high-dimensional data: A review}},
url = {http://www.sciencedirect.com/science/article/pii/S0167947312004422},
volume = {71},
year = {2014}
}
@article{bouguila2004unsupervised,
abstract = {This paper presents an unsupervised algorithm for learning a finite mixture model from multivariate data. This mixture model is based on the Dirichlet distribution, which offers high flexibility for modeling data. The proposed approach for estimating the parameters of a Dirichlet mixture is based on the maximum likelihood (ML) and Fisher scoring methods. Experimental results are presented for the following applications: estimation of artificial histograms, summarization of image databases for efficient retrieval, and human skin color modeling and its application to skin detection in multimedia databases.},
author = {Bouguila, Nizar and Ziou, Djemel and Vaillancourt, Jean},
doi = {10.1109/TIP.2004.834664},
issn = {10577149},
journal = {IEEE Transactions on Image Processing},
pages = {1533--1543},
pmid = {15540460},
title = {{Unsupervised learning of a finite mixture model based on the Dirichlet distribution and its application}},
volume = {13},
year = {2004}
}
@article{bouguila2011count,
abstract = {In this paper, we consider the problem of constructing accurate and flexible statistical representations for count data, which we often confront in many areas such as data mining, computer vision, and information retrieval. In particular, we analyze and compare several generative approaches widely used for count data clustering, namely multinomial, multinomial Dirichlet, and multinomial generalized Dirichlet mixture models. Moreover, we propose a clustering approach via a mixture model based on a composition of the Liouville family of distributions, from which we select the Beta-Liouville distribution, and the multinomial. The novel proposed model, which we call multinomial Beta-Liouville mixture, is optimized by deterministic annealing expectation-maximization and minimum description length, and strives to achieve a high accuracy of count data clustering and model selection. An important feature of the multinomial Beta-Liouville mixture is that it has fewer parameters than the recently proposed multinomial generalized Dirichlet mixture. The performance evaluation is conducted through a set of extensive empirical experiments, which concern text and image texture modeling and classification and shape modeling, and highlights the merits of the proposed models and approaches.},
author = {Bouguila, Nizar},
doi = {10.1109/TNN.2010.2091428},
issn = {10459227},
journal = {IEEE Transactions on Neural Networks},
keywords = {Count data,Dirichlet,Fisher kernel,Liouville,deterministic annealing expectation-maximization,finite mixture models,generalized Dirichlet,model selection,multinomial,shape modeling,support vector machine,text categorization,texture classification},
pages = {186--198},
pmid = {21095862},
title = {{Count data modeling and classification using finite mixtures of distributions}},
volume = {22},
year = {2011}
}
@inproceedings{bickel2004multi,
abstract = {We consider clustering problems in which the available attributes can be split into two independent subsets, such that either subset suffices for learning. Example applications of this multi-view setting include clustering of Web pages which have an intrinsic view (the pages themselves) and an extrinsic view (e.g., anchor texts of inbound hyperlinks); multi-view learning has so far been studied in the context of classification. We develop and study partitioning and agglomerative, hierarchical multi-view clustering algorithms for text data. We find empirically that the multi-view versions of k-means and EM greatly improve on their single-view counterparts. By contrast, we obtain negative results for agglomerative hierarchical multi-view clustering. Our analysis explains this surprising phenomenon.},
address = {Brighton},
annote = {Mixtures de multinomials},
author = {Bickel, Steffen and Scheffer, Tobias},
booktitle = {ICDM 2004, fourth IEEE International Conference on Data Mining},
doi = {10.1109/ICDM.2004.10095},
editor = {Rastogi, Rajeev and Morik, Katharina and Bramer, Max and Wu, Xindong},
isbn = {0769521428},
pages = {19--26},
pmid = {17235365},
publisher = {IEEE Computer Society},
title = {{Multi-view clustering}},
year = {2004}
}
@misc{baudry2010combining,
abstract = {Model-based clustering consists of fitting a mixture model to data and identifying each cluster with one of its components. Multivariate normal distributions are typically used. The number of clusters is usually determined from the data, often using BIC. In practice, however, individual clusters can be poorly fitted by Gaussian distributions, and in that case model-based clustering tends to represent one non-Gaussian cluster by a mixture of two or more Gaussian distributions. If the number of mixture components is interpreted as the number of clusters, this can lead to overestimation of the number of clusters. This is because BIC selects the number of mixture components needed to provide a good approximation to the density, rather than the number of clusters as such. We propose first selecting the total number of Gaussian mixture components, K, using BIC and then combining them hierarchically according to an entropy criterion. This yields a unique soft clustering for each number of clusters less than or equal to K. These clusterings can be compared on substantive grounds, and we also describe an automatic way of selecting the number of clusters via a piecewise linear regression fit to the rescaled entropy plot. We illustrate the method with simulated data and a flow cytometry dataset. Supplemental Materials are available on the journal Web site and described at the end of the paper.},
author = {Baudry, Jean-Patrick and Raftery, Adrian E. and Celeux, Gilles and Lo, Kenneth and Gottardo, Rapha\"{e}l},
booktitle = {Journal of Computational and Graphical Statistics},
doi = {10.1198/jcgs.2010.08111},
issn = {1061-8600},
pages = {332--353},
pmid = {20953302},
title = {{Combining Mixture Components for Clustering}},
volume = {19},
year = {2010}
}
@article{barcelo1999comment,
author = {Barcel\'{o}-Vidal, Carles and Mart\'{\i}n-Fern\'{a}ndez, Josep A and Pawlowsky-Glahn, Vera},
doi = {10.1023/A:1007520124870},
isbn = {0882-8121},
journal = {Mathematical Geology},
number = {5},
pages = {581--585},
publisher = {Kluwer Academic Publishers-Plenum Publishers},
title = {{Comment on ``Singularity and Nonnormality in the Classification of Compositional Data'' by Bohling, G. C., Davis, J. C. , Olea, R. A. and Harff, J.}},
url = {http://dx.doi.org/10.1023/A:1007520124870},
volume = {31},
year = {1999}
}
@article{banfield1993model,
abstract = {The classification maximum likelihood approach is sufficiently general to encompass many current clustering algorithms, including those based on the sum of squares criterion and on the criterion of Friedman and Rubin (1967, Journal of the American Statistical Association 62, 1159-1178). However, as currently implemented, it does not allow the specification of which features (orientation, size, and shape) are to be common to all clusters and which may differ between clusters. Also, it is restricted to Gaussian distributions and it does not allow for noise. We propose ways of overcoming these limitations. A reparameterization of the covariance matrix allows us to specify that some, but not all, features be the same for all clusters. A practical framework for non-Gaussian clustering is outlined, and a means of incorporating noise in the form of a Poisson process is described. An approximate Bayesian method for choosing the number of clusters is given. The performance of the proposed methods is studied by simulation, with encouraging results. The methods are applied to the analysis of a data set arising in the study of diabetes, and the results seem better than those of previous analyses. A magnetic resonance image (MRI) of the brain is also analyzed, and the methods appear successful in extracting the main features of anatomical interest. The methods described here have been implemented in both Fortran and S-PLUS versions, and the software is freely available through StatLib.},
author = {Banfield, Jeffrey and Raftery, Adrian E.},
doi = {10.2307/2532201},
isbn = {0006341X},
issn = {0006341X},
journal = {Biometrics},
pages = {803--821},
title = {{Model-based Gaussian and Non-Gaussian Clustering}},
volume = {49},
year = {1993}
}
@article{banerjee2005clustering,
author = {Banerjee, Arindam and Dhillon, Inderjit S and Ghosh, Joydeep and Sra, Suvrit},
issn = {1532-4435},
journal = {The Journal of Machine Learning Research},
month = dec,
pages = {1345--1382},
publisher = {JMLR.org},
title = {{Clustering on the Unit Hypersphere Using Von Mises-Fisher Distributions}},
url = {http://dl.acm.org/citation.cfm?id=1046920.1088718},
volume = {6},
year = {2005}
}
@misc{uci2007repository,
abstract = {The UCI Machine Learning Repository is a collection of databases, domain theories, and data generators that are used by the machine learning community for the empirical analysis of machine learning algorithms. The archive was created as an ftp archive in 1987 by David Aha and fellow graduate students at UC Irvine. Since that time, it has been widely used by students, educators, and researchers all over the world as a primary source of machine learning data sets. As an indication of the impact of the archive, it has been cited over 1000 times, making it one of the top 100 most cited "papers" in all of computer science. The current version of the web site was designed in 2007 by Arthur Asuncion and David Newman, and this project is in collaboration with Rexa.info at the University of Massachusetts Amherst. Funding support from the National Science Foundation is gratefully acknowledged.},
author = {Asuncion, A and Newman, D J},
booktitle = {University of California Irvine School of Information},
file = {:home/marc/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Asuncion, Newman - 2007 - UCI Machine Learning Repository.pdf:pdf},
pages = {0},
title = {{UCI Machine Learning Repository}},
url = {http://www.ics.uci.edu/~mlearn/MLRepository.html},
volume = {2008},
year = {2007}
}
@article{andrews2012model,
abstract = {The last decade has seen an explosion of work on the use of mixture models for clustering. The use of the Gaussian mixture model has been common practice, with constraints sometimes imposed upon the component covariance matrices to give families of mixture models. Similar approaches have also been applied, albeit with less fecundity, to classification and discriminant analysis. In this paper, we begin with an introduction to model-based clustering and a succinct account of the state-of-the-art. We then put forth a novel family of mixture models wherein each component is modeled using a multivariate t -distribution with an eigen-decomposed covariance structure. This family, which is largely a t -analogue of the well-known MCLUST family, is known as the t EIGEN family. The efficacy of this family for clustering, classification, and discriminant analysis is illustrated with both real and simulated data. The performance of this family is compared to its Gaussian counterpart on three real data sets.},
author = {Andrews, Jeffrey L. and McNicholas, Paul D.},
doi = {10.1007/s11222-011-9272-x},
isbn = {1122201192},
issn = {09603174},
journal = {Statistics and Computing},
keywords = {Classification,Clustering,Discriminant analysis,Eigen-decomposition,Mixture models,Model-based clustering,Multivariate t-distribution},
pages = {1021--1029},
title = {{Model-based clustering, classification, and discriminant analysis via mixtures of multivariate t-distributions: The tEIGEN family}},
volume = {22},
year = {2012}
}
@article{albert1982mixtures,
abstract = {Assuming a multinomial sampling model, prior distributions are developed which can accept prior information about symmetry and independence in a two-way contingency table. Bayesian estimates for the cell probabilities are obtained from the posterior distributions which are attractive alternatives to the usual classical estimates when vague prior information about symmetry or independence is available.},
author = {Albert, James H. and Gupta, Arjun K.},
doi = {10.1214/aos/1176345991},
issn = {0090-5364},
journal = {The Annals of Statistics},
number = {4},
pages = {1261--1268},
title = {{Mixtures of Dirichlet Distributions and Estimation in Contingency Tables}},
volume = {10},
year = {1982}
}
@article{aitchison1986statistical,
abstract = {The simplex plays an important role as sample space in many practical situations where compositional data, in the form of proportions of some whole, require interpretation. It is argued that the statistical analysis of such data has proved difficult because of a lack both of concepts of independence and of rich enough parametric classes of distributions in the simplex. A variety of independence hypotheses are introduced and interrelated, and new classes of transformed-normal distributions in the simplex are provided as models within which the independence hypotheses can be tested through standard theory of parametric hypothesis testing. The new concepts and statistical methodology are illustrated by a number of applications.},
author = {Aitchison, John},
doi = {10.2307/2345821},
isbn = {00359246},
issn = {0035-9246},
journal = {Journal of the Royal Statistical Society. Series B. Methodological},
pages = {139--177},
title = {{The Statistical Analysis of Compositional Data}},
url = {http://links.jstor.org/sici?sici=0035-9246(1982)44:2<139:TSAOCD>2.0.CO$\backslash$n2-9\&origin=MSN$\backslash$npapers2://publication/uuid/D7E07C14-661F-49B0-B887-CFF0DCF0F38A},
volume = {44},
year = {1982}
}
@article{Grau2013,
abstract = {OBJECTIVE: The objective of this study is to compare the clinical performance of different strategies, REASON, PREVALENT, Inter-Society Consensus (ISC), and the American College of Cardiology/American Heart Association (ACC/AHA) Guidelines, in the selection of candidates for peripheral artery disease (PAD) screening using ankle-brachial index (ABI). METHOD: Our work is a population-based cross-sectional study conducted in Extremadura (Spain) in 2007-2009. Participants were ≥50years old and free of cardiovascular disease. ABI and cardiovascular risk factors were measured. RESULT: In total, 1288 individuals (53\% women), with a mean age of 63years (standard deviation (SD) 9) were included. The prevalence of ABI <0.9 was 4.9\%. REASON risk score identified 53\% of the sample to screen with sensitivity of 87.3\%, quite similar to that identified in ISC and ACC/AHA strategies (both 90.5\%), and specificity of 48.3\%, higher than that of the ISC (30.9\%) and ACC/AHA (31.1\%) strategies. Although the Youden index was 0.4 for both REASON and PREVALENT risk scores, the latter's sensitivity was 60.3\%, almost 30 points less than all other strategies. CONCLUSION: REASON risk score was the strategy with the highest clinical performance and efficiency, with sensitivity of 87.3\% and specificity higher than that of the ISC and ACC/AHA strategies. Although very specific, the PREVALENT strategy had low sensitivity making it difficult to be implemented as a screening tool.},
author = {Grau, Maria and Baena-D\'{\i}ez, Jose-Miguel and F\'{e}lix-Redondo, Francisco-Javier and Fern\'{a}ndez-Berges, Daniel and Comas-Cuf\'{\i}, Marc and For\'{e}s, Rosa and Marrugat, Jaume and Ramos, Rafel},
doi = {10.1016/j.ypmed.2013.06.007},
issn = {1096-0260},
journal = {Preventive medicine},
keywords = {Atherosclerosis,Peripheral artery disease,Primary prevention,Risk factors,Screening,ankle-brachial index},
number = {4},
pages = {328--33},
pmid = {23769902},
publisher = {Elsevier Inc.},
title = {{Estimating the risk of peripheral artery disease using different population strategies.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23769902},
volume = {57},
year = {2013}
}
@article{Ponjoan2014,
abstract = {Introduction: Blood pressure increases in cold periods, but its implications on prevalence of hypertension and on individual progression to hypertension remain unclear. Our aim was to develop a pre-screening test for identifying candidates to suffer hypertension only in cold months among non-hypertensive subjects. Methods: We included 95,277 subjects registered on a primary care database from Girona (Catalonia, Spain), with ≥3 blood pressure measures recorded between 2003 and 2009 and distributed in both cold (October-March) and warm (April-September) periods. We defined four blood pressure patterns depending on the presence of hypertension through these periods. A Cox model determined the risk to develop vascular events associated with blood pressure patterns. A logistic regression distinguished those nonhypertensive individuals who are more prone to suffer cold-induced hypertension. Validity was assessed on the basis of calibration (using Brier score) and discrimination (using the area under the receiver operating characteristics). Results: In cold months, the mean systolic blood pressure increased by 3.3±0.1. mmHg and prevalence of hypertension increased by 8.2\%. Cold-induced hypertension patients were at higher vascular events risk (Hazard ratio=1.44 [95\% Confidence interval 1.15-1.81]), than nonhypertensive individuals. We identified age, diabetes, body mass index and prehypertension as the major contributing factors to cold-induced hypertension onset. Discussion: Hypertension follows a seasonal pattern in some individuals. We recommend screening for hypertension during the cold months, at least in those nonhypertensive individuals identified as cold-induced hypertensive by this assessment tool. © 2014 Elsevier Inc.},
author = {Ponjoan, Ana and Garc\'{\i}a-Gil, Maria M. and Mart\'{\i}, Ruth and Comas-Cuf\'{\i}, Marc and Alves-i-Cabratosa, Lia and Sala, J. and Marrugat, Jaume and Elosua, R. and de Tuero, G. Coll and Grau, Maria and Ramos, Rafel},
journal = {Environmental Research},
keywords = {Blood pressure,Season,Temperature,Vascular disease,Winter},
pages = {190--196},
pmid = {24792416},
publisher = {Academic Press Inc.},
title = {{Derivation and validation of BOREAS, a risk score identifying candidates to develop cold-induced hypertension}},
volume = {132},
year = {2014}
}
@article{Comas2009,
abstract = {In this paper, we analyze parameter improvement under vertex fusion in a graph G. This is a setting in which a new graph G??? is obtained after identifying a subset of vertices of G in a single vertex. We are interested in distance parameters, in particular diameter, radius and eccentricity of a vertex v. We show that the corresponding problem is NP-Complete for the three parameters. We also find graph classes in which the problem can be solved in polynomial time. ?? 2009 Elsevier Ltd. All rights reserved.},
author = {Comas, Marc and Serna, Maria},
journal = {European Journal of Combinatorics},
number = {7},
pages = {1612--1623},
title = {{Vertex fusion under distance constraints}},
volume = {30},
year = {2009}
}
@article{Comas2007,
abstract = {Given a graph G = (V, E), a positive integer k, and a positive integer d, we want find a subset V k with k vertices such the graph obtained by identifying the vertices from V k in G has diameter at most d. We prove that for every d ??? 2 the problem is NP-complete. For the case of trees we provide a polynomial time algorithm that exploits the relationship with the r-dominating set problem. ?? 2007 Elsevier B.V. All rights reserved.},
author = {Comas, Marc and Serna, Maria},
journal = {Electronic Notes in Discrete Mathematics},
keywords = {Augmentation problems,graph diameter,r-dominating set},
number = {SPEC. ISS.},
pages = {261--265},
title = {{Vertex fusion under diameter constraints}},
volume = {29},
year = {2007}
}
