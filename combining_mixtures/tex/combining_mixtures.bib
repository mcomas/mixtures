@article{martin2012model,
address = {Amsterdam, The Netherlands, The Netherlands},
author = {Mart\'{\i}n-Fern\'{a}ndez, Josep A. and Hron, Karel and Templ, Mathias and Filzmoser, Peter and Palarea-Albaladejo, Javier},
doi = {10.1016/j.csda.2012.02.012},
issn = {0167-9473},
journal = {Comput. Stat. Data Anal.},
keywords = {Balances,EM algorithm,Log-ratio transformations,Robust regression,Values below detection limit},
number = {9},
pages = {2688--2704},
publisher = {Elsevier Science Publishers B. V.},
title = {{Model-based Replacement of Rounded Zeros in Compositional Data: Classical and Robust Approaches}},
url = {http://dx.doi.org/10.1016/j.csda.2012.02.012},
volume = {56},
year = {2012}
}
@article{mateu2007skew,
author = {Mateu-Figueras, Gl\`{o}ria and Pawlowsky-Glahn, Vera},
doi = {10.1080/03610920601126258},
journal = {Communications in Statistics - Theory and Methods},
number = {9},
pages = {1787--1802},
title = {{The Skew-Normal Distribution on the Simplex}},
url = {http://dx.doi.org/10.1080/03610920601126258},
volume = {36},
year = {2007}
}
@article{papageorgiou2001model,
author = {Papageorgiou, Ioulia and Baxter, M J and Cau, M A},
doi = {10.1111/1475-4754.00037},
issn = {1475-4754},
journal = {Archaeometry},
keywords = {CERAMIC COMPOSITIONS,CLASSIFICATION MAXIMUM-LIKELIHOOD,CLUSTER ANALYSIS,LEAD ISOTOPE DATA,MIXTURE MAXIMUM-LIKELIHOOD,OUTLIERS},
number = {4},
pages = {571--588},
publisher = {Blackwell Publishers Ltd},
title = {{Model-based Cluster Analysis of Artefact Compositional Data}},
url = {http://dx.doi.org/10.1111/1475-4754.00037},
volume = {43},
year = {2001}
}
@article{Ponjoan2014,
abstract = {Introduction: Blood pressure increases in cold periods, but its implications on prevalence of hypertension and on individual progression to hypertension remain unclear. Our aim was to develop a pre-screening test for identifying candidates to suffer hypertension only in cold months among non-hypertensive subjects. Methods: We included 95,277 subjects registered on a primary care database from Girona (Catalonia, Spain), with ≥3 blood pressure measures recorded between 2003 and 2009 and distributed in both cold (October-March) and warm (April-September) periods. We defined four blood pressure patterns depending on the presence of hypertension through these periods. A Cox model determined the risk to develop vascular events associated with blood pressure patterns. A logistic regression distinguished those nonhypertensive individuals who are more prone to suffer cold-induced hypertension. Validity was assessed on the basis of calibration (using Brier score) and discrimination (using the area under the receiver operating characteristics). Results: In cold months, the mean systolic blood pressure increased by 3.3±0.1. mmHg and prevalence of hypertension increased by 8.2\%. Cold-induced hypertension patients were at higher vascular events risk (Hazard ratio=1.44 [95\% Confidence interval 1.15-1.81]), than nonhypertensive individuals. We identified age, diabetes, body mass index and prehypertension as the major contributing factors to cold-induced hypertension onset. Discussion: Hypertension follows a seasonal pattern in some individuals. We recommend screening for hypertension during the cold months, at least in those nonhypertensive individuals identified as cold-induced hypertensive by this assessment tool. © 2014 Elsevier Inc.},
author = {Ponjoan, Ana and Garc\'{\i}a-Gil, Maria M. and Mart\'{\i}, Ruth and Comas-Cuf\'{\i}, Marc and Alves-i-Cabratosa, Lia and Sala, J. and Marrugat, Jaume and Elosua, R. and de Tuero, G. Coll and Grau, Maria and Ramos, Rafel},
journal = {Environmental Research},
keywords = {Blood pressure,Season,Temperature,Vascular disease,Winter},
pages = {190--196},
pmid = {24792416},
publisher = {Academic Press Inc.},
title = {{Derivation and validation of BOREAS, a risk score identifying candidates to develop cold-induced hypertension}},
volume = {132},
year = {2014}
}
@article{Baneshi2012,
abstract = {BACKGROUND: Prognostic models have clinical appeal to aid therapeutic decision making. Two main practical challenges in development of such models are assessment of validity of models and imputation of missing data. In this study, importance of imputation of missing data and application of bootstrap technique in development, simplification, and assessment of internal validity of a prognostic model is highlighted. METHODS: Overall, 310 breast cancer patients were recruited. Missing data were imputed 10 times. Then to deal with sensitivity of the model due to small changes in the data (internal validity), 100 bootstrap samples were drawn from each of 10 imputed data sets leading to 1000 samples. A Cox regression model was fitted to each of 1000 samples. Only variables retained in more than 50\% of samples were used in development of final model. RESULTS: Four variables retained significant in more than 50\% (i.e. 500 samples) of bootstrap samples; tumour size (91\%), tumour grade (64\%), history of benign breast disease (77\%), and age at diagnosis (59\%). Tumour size was the strongest predictor with inclusion frequency exceeding 90\%. Number of deliveries was correlated with age at diagnosis (r=0.35, P<0.001). These two variables together retained significant in more than 90\% of samples. CONCLUSION: We addressed two important methodological issues using a cohort of breast cancer patients. The algorithm combines multiple imputation of missing data and bootstrapping and has the potential to be applied in all kind of regression modelling exercises so as to address internal validity of models.},
author = {Baneshi, Mr and Talei, A},
file = {:Users/marc/Library/Application Support/Mendeley Desktop/Downloaded/Baneshi, Talei - 2012 - Assessment of Internal Validity of Prognostic Models through Bootstrapping and Multiple Imputation of Missing Da.pdf:pdf},
issn = {2251-6085},
journal = {Iranian journal of public health},
keywords = {bootstrap,breast neoplasm,internal validity,missing data,multiple imputation},
month = jan,
number = {5},
pages = {110--5},
pmid = {23113185},
title = {{Assessment of Internal Validity of Prognostic Models through Bootstrapping and Multiple Imputation of Missing Data.}},
volume = {41},
year = {2012}
}
@inproceedings{bickel2004multi,
abstract = {We consider clustering problems in which the available attributes can be split into two independent subsets, such that either subset suffices for learning. Example applications of this multi-view setting include clustering of Web pages which have an intrinsic view (the pages themselves) and an extrinsic view (e.g., anchor texts of inbound hyperlinks); multi-view learning has so far been studied in the context of classification. We develop and study partitioning and agglomerative, hierarchical multi-view clustering algorithms for text data. We find empirically that the multi-view versions of k-means and EM greatly improve on their single-view counterparts. By contrast, we obtain negative results for agglomerative hierarchical multi-view clustering. Our analysis explains this surprising phenomenon.},
address = {Brighton},
annote = {Mixtures de multinomials},
author = {Bickel, Steffen and Scheffer, Tobias},
booktitle = {ICDM 2004, fourth IEEE International Conference on Data Mining},
doi = {10.1109/ICDM.2004.10095},
editor = {Rastogi, Rajeev and Morik, Katharina and Bramer, Max and Wu, Xindong},
isbn = {0769521428},
pages = {19--26},
pmid = {17235365},
publisher = {IEEE Computer Society},
title = {{Multi-view clustering}},
year = {2004}
}
@article{dempster1977maximum,
abstract = {A broadly applicable algorithm for computing maximum likelihood estimates from incomplete data is presented at various levels of generality. Theory showing the monotone behaviour of the likelihood and convergence of the algorithm is derived. Many examples are sketched, including missing value situations, applications to grouped, censored or truncated data, finite mixture models, variance component estimation, hyperparameter estimation, iteratively reweighted least squares and factor analysis.},
archivePrefix = {arXiv},
arxivId = {0710.5696v2},
author = {Dempster, A. P. and Laird, N. M. and Rubin, D. B.},
doi = {10.1.1.133.4884},
eprint = {0710.5696v2},
isbn = {0000000779},
issn = {00359246},
journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
pages = {1--38},
pmid = {9501024},
title = {{Maximum likelihood from incomplete data via the EM algorithm}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.133.4884},
volume = {39},
year = {1977}
}
@article{Grau2013,
abstract = {OBJECTIVE: The objective of this study is to compare the clinical performance of different strategies, REASON, PREVALENT, Inter-Society Consensus (ISC), and the American College of Cardiology/American Heart Association (ACC/AHA) Guidelines, in the selection of candidates for peripheral artery disease (PAD) screening using ankle-brachial index (ABI). METHOD: Our work is a population-based cross-sectional study conducted in Extremadura (Spain) in 2007-2009. Participants were ≥50years old and free of cardiovascular disease. ABI and cardiovascular risk factors were measured. RESULT: In total, 1288 individuals (53\% women), with a mean age of 63years (standard deviation (SD) 9) were included. The prevalence of ABI <0.9 was 4.9\%. REASON risk score identified 53\% of the sample to screen with sensitivity of 87.3\%, quite similar to that identified in ISC and ACC/AHA strategies (both 90.5\%), and specificity of 48.3\%, higher than that of the ISC (30.9\%) and ACC/AHA (31.1\%) strategies. Although the Youden index was 0.4 for both REASON and PREVALENT risk scores, the latter's sensitivity was 60.3\%, almost 30 points less than all other strategies. CONCLUSION: REASON risk score was the strategy with the highest clinical performance and efficiency, with sensitivity of 87.3\% and specificity higher than that of the ISC and ACC/AHA strategies. Although very specific, the PREVALENT strategy had low sensitivity making it difficult to be implemented as a screening tool.},
author = {Grau, Maria and Baena-D\'{\i}ez, Jose-Miguel and F\'{e}lix-Redondo, Francisco-Javier and Fern\'{a}ndez-Berges, Daniel and Comas-Cuf\'{\i}, Marc and For\'{e}s, Rosa and Marrugat, Jaume and Ramos, Rafel},
doi = {10.1016/j.ypmed.2013.06.007},
issn = {1096-0260},
journal = {Preventive medicine},
keywords = {Atherosclerosis,Peripheral artery disease,Primary prevention,Risk factors,Screening,ankle-brachial index},
number = {4},
pages = {328--33},
pmid = {23769902},
publisher = {Elsevier Inc.},
title = {{Estimating the risk of peripheral artery disease using different population strategies.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23769902},
volume = {57},
year = {2013}
}
@inproceedings{ongaro2008new,
abstract = {The Dirichlet family owes its privileged status within simplex distributions to easyness of interpretation and good mathematical properties. In particular, we recall fundamental properties for the analysis of compositional data such as closure under amalgamation and subcomposition. From a probabilistic point of view, it is characterised (uniquely) by a variety of independence relationships which makes it indisputably the reference model for expressing the non trivial idea of substantial independence for compositions. Indeed, its well known inadequacy as a general model for compositional data stems from such an independence structure together with the poorness of its parametrisation. In this paper a new class of distributions (called Flexible Dirichlet) capable of handling various dependence structures and containing the Dirichlet as a special case is presented. The new model exhibits a considerably richer parametrisation which, for example, allows to model the means and (part of) the variance-covariance matrix separately. Moreover, such a model preserves some good mathematical properties of the Dirichlet, i.e. closure under amalgamation and subcomposition with new parameters simply related to the parent composition parameters. Furthermore, the joint and conditional distributions of subcompositions and relative totals can be expressed as simple mixtures of two Flexible Dirichlet distributions. The basis generating the Flexible Dirichlet, though keeping compositional invariance, shows a dependence structure which allows various forms of partitional dependence to be contemplated by the model (e.g. non-neutrality, subcompositional dependence and subcompositional non-invariance), independence cases being identified by suitable parameter configurations. In particular, within this model substantial independence among subsets of components of the composition naturally occurs when the subsets have a Dirichlet distribution},
address = {Girona},
author = {Ongaro, Andrea and Migliorati, Sonia and Monti, Gianna Serafina},
booktitle = {CoDaWork 2008, the 3rd International Workshop on Compositional Data Analysis},
editor = {Daunis-i-Estadella, Josep and Mart\'{\i}n-Fern\'{a}ndez, Josep A.},
file = {:Users/marc/Library/Application Support/Mendeley Desktop/Downloaded/Ongaro, Migliorati, Monti - 2008 - A new distribution on the simplex containing the Dirichlet family.pdf:pdf},
keywords = {Dirichlet,Invari\`{a}ncia,Models matem\`{a}tics,Principi de},
language = {eng},
month = may,
organization = {Universitat de Girona.},
title = {{A new distribution on the simplex containing the Dirichlet family}},
url = {http://dugi-doc.udg.edu//handle/10256/726},
year = {2008}
}
@article{pawlowsky2001geometric,
author = {Pawlowsky-Glahn, Vera and Egozcue, Juan Jos\'{e}},
doi = {10.1007/s004770100077},
issn = {1436-3240},
journal = {Stochastic Environmental Research and Risk Assessment},
keywords = {Euclidean space,Key words: Aitchison geometry,compositional data,finite dimensional Hilbert space,metric center,metric variance.},
language = {English},
number = {5},
pages = {384--398},
publisher = {Springer-Verlag},
title = {{Geometric approach to statistical analysis on the simplex}},
url = {http://dx.doi.org/10.1007/s004770100077},
volume = {15},
year = {2001}
}
@article{Steyerberg2010,
abstract = {The performance of prediction models can be assessed using a variety of methods and metrics. Traditional measures for binary and survival outcomes include the Brier score to indicate overall model performance, the concordance (or c) statistic for discriminative ability (or area under the receiver operating characteristic [ROC] curve), and goodness-of-fit statistics for calibration.Several new measures have recently been proposed that can be seen as refinements of discrimination measures, including variants of the c statistic for survival, reclassification tables, net reclassification improvement (NRI), and integrated discrimination improvement (IDI). Moreover, decision-analytic measures have been proposed, including decision curves to plot the net benefit achieved by making decisions based on model predictions.We aimed to define the role of these relatively novel approaches in the evaluation of the performance of prediction models. For illustration, we present a case study of predicting the presence of residual tumor versus benign tissue in patients with testicular cancer (n = 544 for model development, n = 273 for external validation).We suggest that reporting discrimination and calibration will always be important for a prediction model. Decision-analytic measures should be reported if the predictive model is to be used for clinical decisions. Other measures of performance may be warranted in specific applications, such as reclassification metrics to gain insight into the value of adding a novel predictor to an established model.},
author = {Steyerberg, Ewout W and Vickers, Andrew J and Cook, Nancy R and Gerds, Thomas and Gonen, Mithat and Obuchowski, Nancy and Pencina, Michael J and Kattan, Michael W},
doi = {10.1097/EDE.0b013e3181c30fb2},
file = {:Users/marc/Library/Application Support/Mendeley Desktop/Downloaded/Steyerberg et al. - 2010 - Assessing the performance of prediction models a framework for traditional and novel measures.pdf:pdf},
issn = {1531-5487},
journal = {Epidemiology (Cambridge, Mass.)},
keywords = {Epidemiologic Studies,Models, Statistical,Prognosis,ROC Curve,Reproducibility of Results,Risk Assessment,Risk Assessment: methods,Risk Assessment: standards,Risk Assessment: statistics \& numerical data},
month = jan,
number = {1},
pages = {128--38},
pmid = {20010215},
title = {{Assessing the performance of prediction models: a framework for traditional and novel measures.}},
volume = {21},
year = {2010}
}
@misc{uci2007repository,
abstract = {The UCI Machine Learning Repository is a collection of databases, domain theories, and data generators that are used by the machine learning community for the empirical analysis of machine learning algorithms. The archive was created as an ftp archive in 1987 by David Aha and fellow graduate students at UC Irvine. Since that time, it has been widely used by students, educators, and researchers all over the world as a primary source of machine learning data sets. As an indication of the impact of the archive, it has been cited over 1000 times, making it one of the top 100 most cited "papers" in all of computer science. The current version of the web site was designed in 2007 by Arthur Asuncion and David Newman, and this project is in collaboration with Rexa.info at the University of Massachusetts Amherst. Funding support from the National Science Foundation is gratefully acknowledged.},
author = {Asuncion, A and Newman, D J},
booktitle = {University of California Irvine School of Information},
file = {:Users/marc/Library/Application Support/Mendeley Desktop/Downloaded/Asuncion, Newman - 2007 - UCI Machine Learning Repository.pdf:pdf},
pages = {0},
title = {{UCI Machine Learning Repository}},
url = {http://www.ics.uci.edu/~mlearn/MLRepository.html},
volume = {2008},
year = {2007}
}
@article{bouveyron2014model,
abstract = {Model-based clustering is a popular tool which is renowned for its probabilistic foundations and its flexibility. However, high-dimensional data are nowadays more and more frequent and, unfortunately, classical model-based clustering techniques show a disappointing behavior in high-dimensional spaces. This is mainly due to the fact that model-based clustering methods are dramatically over-parametrized in this case. However, high-dimensional spaces have specific characteristics which are useful for clustering and recent techniques exploit those characteristics. After having recalled the bases of model-based clustering, dimension reduction approaches, regularization-based techniques, parsimonious modeling, subspace clustering methods and clustering methods based on variable selection are reviewed. Existing softwares for model-based clustering of high-dimensional data will be also reviewed and their practical use will be illustrated on real-world data sets.},
author = {Bouveyron, Charles and Brunet-Saumard, Camille},
doi = {10.1016/j.csda.2012.12.008},
isbn = {01679473},
issn = {01679473},
journal = {Computational Statistics \& Data Analysis},
keywords = {Dimension reduction,High-dimensional data,Model-based clustering,Parsimonious models,R package,Regularization,Software,Subspace clustering,Variable selection},
pages = {52--78},
title = {{Model-based clustering of high-dimensional data: A review}},
url = {http://www.sciencedirect.com/science/article/pii/S0167947312004422},
volume = {71},
year = {2014}
}
@inproceedings{ComasCufi2013,
abstract = {To cluster samples from a finite mixture density a model-based technique is recommended. Initially the cluster method selects the total number of mixture components. Assuming that the number of groups is less than or equal to the mixture components, the method hierarchically combines the components using an entropy criterion applied to posterior probabilities. Typically the criterion is based on the well-known Shannon entropy. In this work we show that any model-based cluster analysis applied to any type of data, not necessarily compositional, is enriched when the vector of posterior or individual’s conditional probabilities (group memberships) are considered as elements of the simplex. In this way, entropy criterion based on the Aitchison distance and the compositional Kullback-Leibler divergence are introduced. Here the Aitchison distance between two compositions is defined as the Euclidean distance between the corresponding log-ratio coordinates. The compositional Kullback-Leibler divergence consists in a modification of the Jeffreys divergence. Both measures fulfil the two main compositional principles: scale invariance and subcompositional coherence. The performance of these compositional entropy criteria are evaluated and illustrated using real and simulated data sets},
address = {London (UK)},
author = {Comas-Cuf\'{\i}, Marc and Mart\'{\i}n-Fern\'{a}ndez, Josep A. and Mateu-Figueras, Gl\`{o}ria},
booktitle = {6th International Conference of the ERCIM (European Research Consortium for Informatics and Mathematics) Working Group on Computational and Methodological Statistics (ERCIM 2013)},
pages = {122},
title = {{Compositional entropies in model based clustering}},
year = {2013}
}
@article{egozcue2005balances,
abstract = {Amalgamation of parts of a composition has been extensively used as a technique of analysis to achieve reduced dimension, as was discussed during the CoDaWork'03 meeting (Girona, Spain, 2003). It was shown to be a non-linear operation in the simplex that does not preserve distances under perturbation. The discussion motivated the introduction in the present paper of concepts such as group of parts, balance between groups, and sequential binary partition, which are intended to provide tools of compositional data analysis for dimension reduction. Key concepts underlying this development are the established tools of subcomposition, coordinates in an orthogonal basis of the simplex, balancing element and, in general, the Aitchison geometry in the simplex. Main new results are: a method to analyze grouped parts of a compositional vector through the adequate coordinates in an ad hoc orthonormal basis; and the study of balances of groups of parts (inter-group analysis) as an orthogonal projection similar to that used in standard subcompositional analysis (intra-group analysis). A simulated example compares results when testing equal centers of two populations using amalgamated parts and balances; it shows that, in certain circumstances, results from both analysis can disagree.},
author = {Egozcue, Juan Jos\'{e} and Pawlowsky-Glahn, Vera},
doi = {10.1007/s11004-005-7381-9},
isbn = {0882-8121},
issn = {08828121},
journal = {Mathematical Geology},
keywords = {Amalgamation,Euclidean geometry,Log-ratio analysis,Orthogonal projection,Simplex,Subcomposition},
pages = {795--828},
title = {{Groups of parts and their balances in compositional data analysis}},
volume = {37},
year = {2005}
}
@article{Gerds2006,
author = {Gerds, Thomas a. and Schumacher, Martin},
doi = {10.1002/bimj.200610301},
file = {:Users/marc/Library/Application Support/Mendeley Desktop/Downloaded/Gerds, Schumacher - 2006 - Consistent Estimation of the Expected Brier Score in General Survival Models with Right-Censored Event Times.pdf:pdf},
issn = {03233847},
journal = {Biometrical Journal},
keywords = {brier score,censoring bias,censoring weighting,inverse of probability of,model validation,survival analysis},
month = dec,
number = {6},
pages = {1029--1040},
title = {{Consistent Estimation of the Expected Brier Score in General Survival Models with Right-Censored Event Times}},
volume = {48},
year = {2006}
}
@article{lee2011fitting,
abstract = {We show how the expectation-maximization (EM) algorithm can be applied exactly for the fitting of mixtures of general multivariate skew t (MST) distributions, eliminating the need for computationally expensive Monte Carlo estimation. Finite mixtures of MST distributions have proven to be useful in modelling heterogeneous data with asymmetric and heavy tail behaviour. Recently, they have been exploited as an effective tool for modelling flow cytometric data. However, without restrictions on the the characterizations of the component skew t-distributions, Monte Carlo methods have been used to fit these models. In this paper, we show how the EM algorithm can be implemented for the iterative computation of the maximum likelihood estimates of the model parameters without resorting to Monte Carlo methods for mixtures with unrestricted MST components. The fast calculation of semi-infinite integrals on the E-step of the EM algorithm is effected by noting that they can be put in the form of moments of the truncated multivariate t-distribution, which subsequently can be expressed in terms of the non-truncated form of the t-distribution function for which fast algorithms are available. We demonstrate the usefulness of the proposed methodology by some applications to three real data sets.},
archivePrefix = {arXiv},
arxivId = {1109.4706},
author = {Lee, Sharon X. and McLachlan, Geoffrey J.},
eprint = {1109.4706},
month = sep,
title = {{On the fitting of mixtures of multivariate skew t-distributions via the EM algorithm}},
url = {http://arxiv.org/abs/1109.4706},
year = {2011}
}
@article{lin2010robust,
author = {Lin, Tsung I},
doi = {10.1007/s11222-009-9128-9},
issn = {0960-3174},
journal = {Statistics and Computing},
keywords = {MCEM-type algorithms,MSN,MST,Multivariate truncated normal,Multivariate truncated t,Outliers},
language = {English},
number = {3},
pages = {343--356},
publisher = {Springer US},
title = {{Robust mixture modeling using multivariate skew t distributions}},
url = {http://dx.doi.org/10.1007/s11222-009-9128-9},
volume = {20},
year = {2010}
}
@article{palarea2014compositional,
author = {Palarea-Albaladejo, Javier and Mart\'{\i}n-Fern\'{a}ndez, Josep A. and Buccianti, Antonella},
doi = {10.1016/j.gexplo.2013.09.003},
issn = {03756742},
journal = {Journal of Geochemical Exploration},
month = jun,
pages = {71--77},
title = {{Compositional methods for estimating elemental concentrations below the limit of detection in practice using R}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0375674213001866},
volume = {141},
year = {2014}
}
@article{rayens1994dependence,
abstract = {Compositional data arise naturally in several branches of science, including chemistry, geology, biology, medicine, ecology, and manufacturing design. Thus the correct statistical analysis of this type of data is of fundamental importance. Prior to the pioneering and extensive work of Aitchison, the Dirichlet distribution provided the parametric model of choice when analyzing such data. But Aitchison and others have since pointed out that the Dirichlet distribution is appropriate only for modeling compositional vectors that exhibit forms of extreme independence. Aitchison developed his logistic normal classes partly in response to this shortcoming. Unfortunately, Aitchison's logistic normal classes do not contain the Dirichlet distribution as a special case. As a result, they exhibit interesting dependence structures but are unable to model extreme independence. The generalized Liouville family is studied in this article. This family, which contains the Dirichlet class, is shown to contain densities that can model either complicated dependence or complicated independence structures.},
author = {Rayens, W S and Srinivasan, C},
doi = {10.2307/2291008},
isbn = {0162-1459},
issn = {01621459},
journal = {Journal of the American Statistical Association},
keywords = {CLOSURE,CODA,COMPOSITIONAL DATA,NEUTRALITY,SUB},
pages = {1465--1470},
title = {{Dependence properties of generalized Liouville distributions on the Simplex}},
url = {<Go to ISI>://A1994PU33000031},
volume = {89},
year = {1994}
}
@misc{baudry2010combining,
abstract = {Model-based clustering consists of fitting a mixture model to data and identifying each cluster with one of its components. Multivariate normal distributions are typically used. The number of clusters is usually determined from the data, often using BIC. In practice, however, individual clusters can be poorly fitted by Gaussian distributions, and in that case model-based clustering tends to represent one non-Gaussian cluster by a mixture of two or more Gaussian distributions. If the number of mixture components is interpreted as the number of clusters, this can lead to overestimation of the number of clusters. This is because BIC selects the number of mixture components needed to provide a good approximation to the density, rather than the number of clusters as such. We propose first selecting the total number of Gaussian mixture components, K, using BIC and then combining them hierarchically according to an entropy criterion. This yields a unique soft clustering for each number of clusters less than or equal to K. These clusterings can be compared on substantive grounds, and we also describe an automatic way of selecting the number of clusters via a piecewise linear regression fit to the rescaled entropy plot. We illustrate the method with simulated data and a flow cytometry dataset. Supplemental Materials are available on the journal Web site and described at the end of the paper.},
author = {Baudry, Jean-Patrick and Raftery, Adrian E. and Celeux, Gilles and Lo, Kenneth and Gottardo, Rapha\"{e}l},
booktitle = {Journal of Computational and Graphical Statistics},
doi = {10.1198/jcgs.2010.08111},
file = {:Users/marc/Library/Application Support/Mendeley Desktop/Downloaded/Baudry et al. - 2010 - Combining Mixture Components for Clustering.pdf:pdf},
issn = {1061-8600},
pages = {332--353},
pmid = {20953302},
title = {{Combining Mixture Components for Clustering}},
volume = {19},
year = {2010}
}
@article{aitchison1982statistical,
abstract = {The simplex plays an important role as sample space in many practical situations where compositional data, in the form of proportions of some whole, require interpretation. It is argued that the statistical analysis of such data has proved difficult because of a lack both of concepts of independence and of rich enough parametric classes of distributions in the simplex. A variety of independence hypotheses are introduced and interrelated, and new classes of transformed-normal distributions in the simplex are provided as models within which the independence hypotheses can be tested through standard theory of parametric hypothesis testing. The new concepts and statistical methodology are illustrated by a number of applications.},
author = {Aitchison, John},
doi = {10.2307/2345821},
isbn = {00359246},
issn = {0035-9246},
journal = {Journal of the Royal Statistical Society. Series B. Methodological},
pages = {139--177},
title = {{The Statistical Analysis of Compositional Data}},
url = {http://links.jstor.org/sici?sici=0035-9246(1982)44:2<139:TSAOCD>2.0.CO$\backslash$n2-9\&origin=MSN$\backslash$npapers2://publication/uuid/D7E07C14-661F-49B0-B887-CFF0DCF0F38A},
volume = {44},
year = {1982}
}
@book{mclachlan2000finite,
author = {McLachlan, Geoffrey J. and Peel, D},
publisher = {John Wiley \& Sons, New York},
title = {{Finite Mixture Models, Willey Series in Probability and Statistics}},
year = {2000}
}
@article{bouguila2004unsupervised,
abstract = {This paper presents an unsupervised algorithm for learning a finite mixture model from multivariate data. This mixture model is based on the Dirichlet distribution, which offers high flexibility for modeling data. The proposed approach for estimating the parameters of a Dirichlet mixture is based on the maximum likelihood (ML) and Fisher scoring methods. Experimental results are presented for the following applications: estimation of artificial histograms, summarization of image databases for efficient retrieval, and human skin color modeling and its application to skin detection in multimedia databases.},
author = {Bouguila, Nizar and Ziou, Djemel and Vaillancourt, Jean},
doi = {10.1109/TIP.2004.834664},
issn = {10577149},
journal = {IEEE Transactions on Image Processing},
pages = {1533--1543},
pmid = {15540460},
title = {{Unsupervised learning of a finite mixture model based on the Dirichlet distribution and its application}},
volume = {13},
year = {2004}
}
@article{DeLong1988,
abstract = {Methods of evaluating and comparing the performance of diagnostic tests are of increasing importance as new tests are developed and marketed. When a test is based on an observed variable that lies on a continuous or graded scale, an assessment of the overall value of the test can be made through the use of a receiver operating characteristic (ROC) curve. The curve is constructed by varying the cutpoint used to determine which values of the observed variable will be considered abnormal and then plotting the resulting sensitivities against the corresponding false positive rates. When two or more empirical curves are constructed based on tests performed on the same individuals, statistical analysis on differences between curves must take into account the correlated nature of the data. This paper presents a nonparametric approach to the analysis of areas under correlated ROC curves, by using the theory on generalized U-statistics to generate an estimated covariance matrix.},
author = {DeLong, E R and DeLong, D M and Clarke-Pearson, D L},
file = {:Users/marc/Library/Application Support/Mendeley Desktop/Downloaded/DeLong, DeLong, Clarke-Pearson - 1988 - Comparing the areas under two or more correlated receiver operating characteristic curves a nonp.pdf:pdf},
issn = {0006-341X},
journal = {Biometrics},
keywords = {Algorithms,Analysis of Variance,Female,Humans,Intestinal Obstruction,Intestinal Obstruction: surgery,Models,Ovarian Neoplasms,Ovarian Neoplasms: complications,Predictive Value of Tests,ROC Curve,Statistical},
month = sep,
number = {3},
pages = {837--45},
pmid = {3203132},
title = {{Comparing the areas under two or more correlated receiver operating characteristic curves: a nonparametric approach.}},
volume = {44},
year = {1988}
}
@article{fraley2002model,
abstract = {Cluster analysis is the automated search for groups of related observations in a dataset. Most clustering done in practice is based largely on heuristic but intuitively reasonable procedures, and most clustering methods available in commercial software are also of this type. However, there is little systematic guidance associated with these methods for solving important practical questions that arise in cluster analysis, such as how many clusters are there, which clustering method should be used, and how should outliers be handled. We review a general methodology for model-based clustering that provides a principled statistical approach to these issues. We also show that this can be useful for other problems in multivariate analysis, such as discriminant analysis and multivariate density estimation. We give examples from medical diagnosis, minefield detection, cluster recovery from noisy data, and spatial density estimation. Finally, we mention limitations of the methodology and discuss recent developments in model-based clustering for non-Gaussian data, high-dimensional datasets, large datasets, and Bayesian estimation. CR - Copyright \&\#169; 2002 American Statistical Association},
author = {Fraley, Chris and Raftery, Adrian E.},
doi = {10.1198/016214502760047131},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
pages = {611--631},
pmid = {20815477},
title = {{Model-Based Clustering, Discriminant Analysis, and Density Estimation}},
volume = {97},
year = {2002}
}
@article{banerjee2005clustering,
author = {Banerjee, Arindam and Dhillon, Inderjit S and Ghosh, Joydeep and Sra, Suvrit},
issn = {1532-4435},
journal = {The Journal of Machine Learning Research},
month = dec,
pages = {1345--1382},
publisher = {JMLR.org},
title = {{Clustering on the Unit Hypersphere using von Mises-Fisher Distributions}},
url = {http://dl.acm.org/citation.cfm?id=1046920.1088718},
volume = {6},
year = {2005}
}
@article{browne2013mixture,
abstract = {We introduce a mixture of generalized hyperbolic distributions as an alternative to the ubiquitous mixture of Gaussian distributions as well as their near relatives of which the mixture of multivariate t and skew-t distributions are predominant. The mathematical development of our mixture of generalized hyperbolic distributions model relies on its relationship with the generalized inverse Gaussian distribution. The latter is reviewed before our mixture models are presented along with details of the aforesaid reliance. Parameter estimation is outlined within the expectation-maximization framework before the performance of our mixture models is illustrated in clustering applications on simulated and real data. In particular, the ability of our models to recover parameters for data from underlying Gaussian, and skew-t distributions is demonstrated. Finally, the role of Generalized hyperbolic mixtures within the wider model-based clustering, classification, and density estimation literature is discussed.},
archivePrefix = {arXiv},
arxivId = {1305.1036},
author = {Browne, Ryan P. and McNicholas, Paul D.},
eprint = {1305.1036},
month = may,
title = {{A Mixture of Generalized Hyperbolic Distributions}},
url = {http://arxiv.org/abs/1305.1036},
year = {2013}
}
@article{celeux1992classification,
abstract = {Setting the optimization-based clustering methods under the classification maximum likelihood approach, we define and study a general Classification EM algorithm. Then, we derive from this algorithm two stochastic algorithms, incorporating random perturbations, to reduce the initial-position dependence of the classical optimization clustering algorithms. Numerical experiments, reported for the variance criterion, show that both stochastic algorithms perform well compared with the standard k-means algorithm which is a particular version of the Classification EM algorithm.},
author = {Celeux, Gilles and Govaert, G\'{e}rard},
doi = {10.1016/0167-9473(92)90042-E},
isbn = {0167-9473},
issn = {01679473},
journal = {Computational Statistics \& Data Analysis},
number = {3},
pages = {315--332},
title = {{A classification EM algorithm for clustering and two stochastic versions}},
volume = {14},
year = {1992}
}
@article{Comas2009,
abstract = {In this paper, we analyze parameter improvement under vertex fusion in a graph G. This is a setting in which a new graph G??? is obtained after identifying a subset of vertices of G in a single vertex. We are interested in distance parameters, in particular diameter, radius and eccentricity of a vertex v. We show that the corresponding problem is NP-Complete for the three parameters. We also find graph classes in which the problem can be solved in polynomial time. ?? 2009 Elsevier Ltd. All rights reserved.},
author = {Comas, Marc and Serna, Maria},
journal = {European Journal of Combinatorics},
number = {7},
pages = {1612--1623},
title = {{Vertex fusion under distance constraints}},
volume = {30},
year = {2009}
}
@article{egozcue2003isometric,
abstract = {Geometry in the simplex has been developed in the last 15 years mainly based on the contributions due to J. Aitchison. The main goal was to develop analytical tools for the statistical analysis of compositional data. Our present aim is to get a further insight into some aspects of this geometry in order to clarify the way for more complex statistical approaches. This is done by way of orthonormal bases, which allow for a straightforward handling of geometric elements in the simplex. The transformation into real coordinates preserves all metric properties and is thus called isometric logratio transformation (ilr). An important result is the decomposition of the simplex, as a vector space, into orthogonal subspaces associated with nonoverlapping subcompositions. This gives the key to join compositions with different parts into a single composition by using a balancing element. The relationship between ilr transformations and the centered-logratio (clr) and additive-logratio (alr) transformations is also studied. Exponential growth or decay of mass is used to illustrate compositional linear processes, parallelism and orthogonality in the simplex.},
author = {Egozcue, Juan Jos\'{e} and Pawlowsky-Glahn, Vera and Mateu-Figueras, Gl\`{o}ria and Barcel\'{o}-Vidal, Carles},
doi = {10.1023/A:1023818214614},
isbn = {0882-8121},
issn = {08828121},
journal = {Mathematical Geology},
keywords = {Aitchison distance,Aitchison geometry,Geodesic,Orthogonal subcompositions,Ternary diagram},
pages = {279--300},
title = {{Isometric Logratio Transformations for Compositional Data Analysis}},
volume = {35},
year = {2003}
}
@article{Gerds2008,
abstract = {For medical decision making and patient information, predictions of future status variables play an important role. Risk prediction models can be derived with many different statistical approaches. To compare them, measures of predictive performance are derived from ROC methodology and from probability forecasting theory. These tools can be applied to assess single markers, multivariable regression models and complex model selection algorithms. This article provides a systematic review of the modern way of assessing risk prediction models. Particular attention is put on proper benchmarks and resampling techniques that are important for the interpretation of measured performance. All methods are illustrated with data from a clinical study in head and neck cancer patients.},
author = {Gerds, Thomas a and Cai, Tianxi and Schumacher, Martin},
doi = {10.1002/bimj.200810443},
file = {:Users/marc/Library/Application Support/Mendeley Desktop/Downloaded/Gerds, Cai, Schumacher - 2008 - The performance of risk prediction models.pdf:pdf},
issn = {1521-4036},
journal = {Biometrical journal. Biometrische Zeitschrift},
keywords = {Algorithms,Benchmarking,Bias (Epidemiology),Decision Making, Computer-Assisted,Head and Neck Neoplasms,Head and Neck Neoplasms: diagnosis,Humans,Models, Statistical,Prognosis,ROC Curve,Risk Assessment,Risk Assessment: methods},
month = aug,
number = {4},
pages = {457--79},
pmid = {18663757},
title = {{The performance of risk prediction models.}},
volume = {50},
year = {2008}
}
@article{hansen1982large,
abstract = {This paper studies estimators that make sample analogues of population orthogonality conditions close to zero. Strong consistency and asymptotic normality of such estimators is established under the assumption that the observable variables are stationary and ergodic. Since many linear and nonlinear econometric estimators reside within the class of estimators studied in this paper, a convenient summary of the large sample properties of these estimators, including some whose large sample properties have not heretofore been discussed, is provided.},
author = {Hansen, Lars Peter},
doi = {10.2307/1912775},
isbn = {00129682},
issn = {00129682},
journal = {Econometrica},
pages = {1029--1054},
pmid = {100},
title = {{Large sample properties of generalized method of moments estimators}},
url = {http://www.jstor.org/stable/1912775},
volume = {50},
year = {1982}
}
@article{Jr1996,
author = {Jr, Frank E Harrell and Lee, Kerry L and Mark, Daniel B},
file = {:Users/marc/Library/Application Support/Mendeley Desktop/Downloaded/Jr, Lee, Mark - 1996 - Tutorial in biostatistics multivariable prognostic models issues in developing models, evaluating assumptions and.pdf:pdf},
pages = {361--387},
title = {{Tutorial in biostatistics multivariable prognostic models: issues in developing models, evaluating assumptions and adequacy, and measuring and reducing errors}},
volume = {15},
year = {1996}
}
@incollection{figueras2011principle,
author = {Mateu-Figueras, Gl\`{o}ria and Pawlowsky-Glahn, Vera and Egozcue, Juan Jos\'{e}},
booktitle = {Compositional Data Analysis},
doi = {10.1002/9781119976462.ch3},
isbn = {9781119976462},
keywords = {Euclidean space structure of simplex - orthonormal,a (D – 1)-dimensional subset - of D-di,and real analysis - using,establishing role of coordinates - in the simplex,mathematical statistics,notation used - standard in compositi,principle of workin,principle of working on coordinates - standard sta,role of coordinates in statistics - standard or cl,similar concepts - for addressing random compositi,simplex SD,standard statistical methodology - traditionally d,the simplex,theory - statistical modeling},
pages = {29--42},
publisher = {John Wiley \& Sons, Ltd},
title = {{The Principle of Working on Coordinates}},
url = {http://dx.doi.org/10.1002/9781119976462.ch3},
year = {2011}
}
@article{prates2013mixsmsn,
author = {Prates, Marcos Oliveira and Lachos, Victor Hugo and Cabral, Celso R\^{o}mulo Barbosa},
issn = {1548-7660},
journal = {Journal of Statistical Software},
number = {12},
title = {{mixsmsn: Fitting Finite Mixture of Scale Mixture of Skew-Normal Distributions}},
url = {http://www.jstatsoft.org/v54/i12},
volume = {54},
year = {2013}
}
@inproceedings{goldberger2005hierarchical,
author = {Goldberger, Jacob and Roweis, Sam},
booktitle = {In NIPS},
file = {:Users/marc/Library/Application Support/Mendeley Desktop/Downloaded/Goldberger, Roweis - 2005 - Hierarchical clustering of a mixture model.pdf:pdf},
pages = {505--512},
publisher = {MIT Press},
title = {{Hierarchical clustering of a mixture model}},
year = {2005}
}
@article{hennig2010methods,
author = {Hennig, Christian},
doi = {10.1007/s11634-010-0058-3},
file = {:Users/marc/Library/Application Support/Mendeley Desktop/Downloaded/Hennig - 2010 - Methods for merging Gaussian mixture components.pdf:pdf},
issn = {1862-5347},
journal = {Advances in Data Analysis and Classification},
keywords = {62H30,Dip test,Model-based cluster analysis,Multilayer mixture,Prediction strength,Ridgeline,Unimodality},
language = {English},
number = {1},
pages = {3--34},
publisher = {Springer-Verlag},
title = {{Methods for merging Gaussian mixture components}},
url = {http://dx.doi.org/10.1007/s11634-010-0058-3},
volume = {4},
year = {2010}
}
@incollection{lee2004combining,
author = {Lee, Hyoung-joo and Cho, Sungzoon},
booktitle = {Intelligent Data Engineering and Automated Learning – IDEAL 2004 SE - 98},
doi = {10.1007/978-3-540-28651-6\_98},
editor = {Yang, ZhengRong and Yin, Hujun and Everson, RichardM.},
file = {:Users/marc/Library/Application Support/Mendeley Desktop/Downloaded/Lee, Cho - 2004 - Combining Gaussian Mixture Models.pdf:pdf},
isbn = {978-3-540-22881-3},
language = {English},
pages = {666--671},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Combining Gaussian Mixture Models}},
url = {http://dx.doi.org/10.1007/978-3-540-28651-6\_98},
volume = {3177},
year = {2004}
}
@article{banfield1993model,
abstract = {The classification maximum likelihood approach is sufficiently general to encompass many current clustering algorithms, including those based on the sum of squares criterion and on the criterion of Friedman and Rubin (1967, Journal of the American Statistical Association 62, 1159-1178). However, as currently implemented, it does not allow the specification of which features (orientation, size, and shape) are to be common to all clusters and which may differ between clusters. Also, it is restricted to Gaussian distributions and it does not allow for noise. We propose ways of overcoming these limitations. A reparameterization of the covariance matrix allows us to specify that some, but not all, features be the same for all clusters. A practical framework for non-Gaussian clustering is outlined, and a means of incorporating noise in the form of a Poisson process is described. An approximate Bayesian method for choosing the number of clusters is given. The performance of the proposed methods is studied by simulation, with encouraging results. The methods are applied to the analysis of a data set arising in the study of diabetes, and the results seem better than those of previous analyses. A magnetic resonance image (MRI) of the brain is also analyzed, and the methods appear successful in extracting the main features of anatomical interest. The methods described here have been implemented in both Fortran and S-PLUS versions, and the software is freely available through StatLib.},
author = {Banfield, Jeffrey and Raftery, Adrian E.},
doi = {10.2307/2532201},
isbn = {0006341X},
issn = {0006341X},
journal = {Biometrics},
pages = {803--821},
title = {{Model-based Gaussian and Non-Gaussian Clustering}},
volume = {49},
year = {1993}
}
@article{connor1969concepts,
abstract = {Concepts of independence for nonnegative continuous random variables, X1,⋯, Xk, subject to the constraint $\Sigma$ Xi = 1 are developed. These concepts provide a means of modeling random vectors of proportions which is useful in analyzing certain kinds of data; and which may be of interest in quantifying prior opinions about multinomial parameters. A generalization of the Dirichlet distribution is given, and its relation to the Dirichlet is simply indicated by means of the concepts. The concepts are used to obtain conclusions of biological interest for data on bone composition in rats and scute growth in turtles.},
author = {Connor, Robert J and Mosimann, James E},
doi = {10.1080/01621459.1969.10500963},
isbn = {01621459},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
pages = {194--206},
title = {{Concepts of Independence for Proportions with a Generalization of the Dirichlet Distribution}},
url = {http://www.jstor.org/stable/2283728},
volume = {64},
year = {1969}
}
@article{li2005clustering,
author = {Li, Jia},
doi = {10.1198/106186005X59586},
file = {:Users/marc/Library/Application Support/Mendeley Desktop/Downloaded/Li - 2005 - Clustering Based on a Multilayer Mixture Model.pdf:pdf},
issn = {1061-8600},
journal = {Journal of Computational and Graphical Statistics},
month = sep,
number = {3},
pages = {547--568},
title = {{Clustering Based on a Multilayer Mixture Model}},
url = {http://www.tandfonline.com/doi/abs/10.1198/106186005X59586},
volume = {14},
year = {2005}
}
@article{longford2014,
abstract = {An index for characterizing the separation of two distributions is introduced. It is applied to assessing whether mixture components are clusters. A related property of being a satellite and a partial ordering of the components are defined. A sequence of clustering structures is defined for a finite mixture with a continuum of thresholds that qualify a cluster. The approach is suitable for outcomes with arbitrary univariate or multivariate distributions and their mixtures. The properties of the index are explored by simulations and on examples.},
address = {1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND},
author = {Longford, Nicholas T and Bartosova, Jitka},
doi = {10.1177/1471082X13503454},
issn = {1471-082X},
journal = {Statistical Modelling},
keywords = {clusters,confusion,mixture,satellite,separation},
month = jun,
number = {3},
pages = {229--255},
publisher = {SAGE PUBLICATIONS LTD},
title = {{A confusion index for measuring separation and clustering}},
type = {Article},
volume = {14},
year = {2014}
}
@article{melnykov2013distribution,
address = {Orlando, FL, USA},
author = {Melnykov, Volodymyr},
doi = {10.1016/j.jmva.2013.07.014},
file = {:Users/marc/Library/Application Support/Mendeley Desktop/Downloaded/Melnykov - 2013 - On the Distribution of Posterior Probabilities in Finite Mixture Models with Application in Clustering.pdf:pdf},
issn = {0047-259X},
journal = {Journal of Multivariate Analysis},
keywords = {62H10,BIC,Delta method,Distribution of posterior probabilities,Entropy,ICL,Model-based clustering,Multivariate Gaussian mixtures},
pages = {175--189},
publisher = {Academic Press, Inc.},
title = {{On the Distribution of Posterior Probabilities in Finite Mixture Models with Application in Clustering}},
url = {http://dx.doi.org/10.1016/j.jmva.2013.07.014},
volume = {122},
year = {2013}
}
@article{Melnykov2012a,
abstract = {The R package MixSim is a new tool that allows simulating mixtures of Gaussian dis- tributions with different levels of overlap between mixture components. Pairwise overlap, defined as a sum of two misclassification probabilities, measures the degree of interaction between components and can be readily employed to control the clustering complexity of datasets simulated from mixtures. These datasets can then be used for systematic performance investigation of clustering and finite mixture modeling algorithms. Among other capabilities of MixSim, there are computing the exact overlap for Gaussianmixtures, simulating Gaussian and non-Gaussian data, simulating outliers and noise variables, calcu- lating various measures of agreement between two partitionings, and constructing parallel distribution plots for the graphical display of finite mixture models. All features of the package are illustrated in great detail. The utility of the package is highlighted through a small comparison study of several popular clustering algorithms.},
author = {Melnykov, Volodymyr and Chen, Wei-Chen and Maitra, Ranjan},
file = {:Users/marc/Library/Application Support/Mendeley Desktop/Downloaded/Melnykov, Chen, Maitra - 2012 - MixSim An R Package for Simulating Data to Study Performance of Clustering Algorithms(2).pdf:pdf},
issn = {15487660},
journal = {Journal of Statistical Software},
keywords = {data simulation,gaussian mixture model,pairwise overlap,parallel distribution},
pages = {1--25},
title = {{MixSim : An R Package for Simulating Data to Study Performance of Clustering Algorithms}},
volume = {51},
year = {2012}
}
@article{pastore2013merging,
author = {Pastore, Andrea and Tonellato, Stefano Federico},
doi = {10.2139/ssrn.2233307},
file = {:Users/marc/Library/Application Support/Mendeley Desktop/Downloaded/Pastore, Tonellato - 2013 - A Merging Algorithm for Gaussian Mixture Components.pdf:pdf},
issn = {1556-5068},
journal = {SSRN Electronic Journal},
number = {04},
title = {{A Merging Algorithm for Gaussian Mixture Components}},
url = {http://www.ssrn.com/abstract=2233307},
year = {2013}
}
@article{ray2005topography,
abstract = {Multivariate normal mixtures provide a flexible method of fitting high-dimensional data. It is shown that their topography, in the sense of their key features as a density, can be analyzed rigorously in lower dimensions by use of a ridgeline manifold that contains all critical points, as well as the ridges of the density. A plot of the elevations on the ridgeline shows the key features of the mixed density. In addition, by use of the ridgeline, we uncover a function that determines the number of modes of the mixed density when there are two components being mixed. A followup analysis then gives a curvature function that can be used to prove a set of modality theorems.},
author = {Ray, Surajit and Lindsay, Bruce G},
file = {:Users/marc/Library/Application Support/Mendeley Desktop/Downloaded/Ray, Lindsay - 2005 - The Topography of Multivariate Normal Mixtures.pdf:pdf},
issn = {00905364},
journal = {The Annals of Statistics},
number = {5},
pages = {pp. 2042--2065},
publisher = {Institute of Mathematical Statistics},
title = {{The Topography of Multivariate Normal Mixtures}},
url = {http://www.jstor.org/stable/3448634},
volume = {33},
year = {2005}
}
@book{aitchison1986statistical,
address = {London (UK)},
annote = {Reprinted in 2003 with additional material by The Blackburn Press},
author = {Aitchison, John},
publisher = {Monographs on Statistics and Applied Probability. Chapman \& Hall Ltd.},
title = {{The Statistical Analysis of Compositional Data}},
year = {1986}
}
@article{albert1982mixtures,
abstract = {Assuming a multinomial sampling model, prior distributions are developed which can accept prior information about symmetry and independence in a two-way contingency table. Bayesian estimates for the cell probabilities are obtained from the posterior distributions which are attractive alternatives to the usual classical estimates when vague prior information about symmetry or independence is available.},
author = {Albert, James H. and Gupta, Arjun K.},
doi = {10.1214/aos/1176345991},
issn = {0090-5364},
journal = {The Annals of Statistics},
number = {4},
pages = {1261--1268},
title = {{Mixtures of Dirichlet Distributions and Estimation in Contingency Tables}},
volume = {10},
year = {1982}
}
@article{bouguila2011count,
abstract = {In this paper, we consider the problem of constructing accurate and flexible statistical representations for count data, which we often confront in many areas such as data mining, computer vision, and information retrieval. In particular, we analyze and compare several generative approaches widely used for count data clustering, namely multinomial, multinomial Dirichlet, and multinomial generalized Dirichlet mixture models. Moreover, we propose a clustering approach via a mixture model based on a composition of the Liouville family of distributions, from which we select the Beta-Liouville distribution, and the multinomial. The novel proposed model, which we call multinomial Beta-Liouville mixture, is optimized by deterministic annealing expectation-maximization and minimum description length, and strives to achieve a high accuracy of count data clustering and model selection. An important feature of the multinomial Beta-Liouville mixture is that it has fewer parameters than the recently proposed multinomial generalized Dirichlet mixture. The performance evaluation is conducted through a set of extensive empirical experiments, which concern text and image texture modeling and classification and shape modeling, and highlights the merits of the proposed models and approaches.},
author = {Bouguila, Nizar},
doi = {10.1109/TNN.2010.2091428},
issn = {10459227},
journal = {IEEE Transactions on Neural Networks},
keywords = {Count data,Dirichlet,Fisher kernel,Liouville,deterministic annealing expectation-maximization,finite mixture models,generalized Dirichlet,model selection,multinomial,shape modeling,support vector machine,text categorization,texture classification},
pages = {186--198},
pmid = {21095862},
title = {{Count data modeling and classification using finite mixtures of distributions}},
volume = {22},
year = {2011}
}
@article{mclachlan2013emmixuskew,
author = {McLachlan, Geoffrey J. and Lee, Sharon X.},
issn = {1548-7660},
journal = {Journal of Statistical Software},
number = {12},
title = {{EMMIXuskew: An R Package for Fitting Mixtures of Multivariate Skew t Distributions via the EM Algorithm}},
url = {http://www.jstatsoft.org/v55/i12},
volume = {55},
year = {2013}
}
@manual{R2014soft,
address = {Vienna, Austria},
author = {{R Core Team}},
organization = {R Foundation for Statistical Computing},
title = {{R: A Language and Environment for Statistical Computing}},
url = {http://www.r-project.org/},
year = {2014}
}
@article{Schumacher2003,
abstract = {OBJECTIVES: A lack of generally applicable tools for the assessment of predictions for survival data has to be recognized. Prediction error curves based on the Brier score that have been suggested as a sensible approach are illustrated by means of a case study. METHODS: The concept of predictions made in terms of conditional survival probabilities given the patient's covariates is introduced. Such predictions are derived from various statistical models for survival data including artificial neural networks. The idea of how the prediction error of a prognostic classification scheme can be followed over time is illustrated with the data of two studies on the prognosis of node positive breast cancer patients, one of them serving as an independent test data set. RESULTS AND CONCLUSIONS: The Brier score as a function of time is shown to be a valuable tool for assessing the predictive performance of prognostic classification schemes for survival data incorporating censored observations. Comparison with the prediction based on the pooled Kaplan Meier estimator yields a benchmark value for any classification scheme incorporating patient's covariate measurements. The problem of an overoptimistic assessment of prediction error caused by data-driven modelling as it is, for example, done with artificial neural nets can be circumvented by an assessment in an independent test data set.},
author = {Schumacher, M and Graf, E and Gerds, T},
doi = {10.1267/METH03050564},
issn = {0026-1270},
journal = {Methods of information in medicine},
keywords = {Breast Neoplasms,Breast Neoplasms: diagnosis,Breast Neoplasms: mortality,Female,Humans,Neoplasms,Neoplasms: diagnosis,Neoplasms: mortality,Neural Networks (Computer),Prognosis,Proportional Hazards Models,Reproducibility of Results,Survival Analysis},
month = jan,
number = {5},
pages = {564--71},
pmid = {14654892},
title = {{How to assess prognostic models for survival data: a case study in oncology.}},
volume = {42},
year = {2003}
}
@article{tian2003bayesian,
author = {Tian, Guo-Liang and Ng, Kai Wang and Geng, Zhi},
journal = {Statistica Sinica},
number = {1},
pages = {189--206},
publisher = {C/O DR HC HO, INST STATISTICAL SCIENCE, ACADEMIA SINICA, TAIPEI 115, TAIWAN},
title = {{Bayesian computation for contingency tables with incomplete cell-counts}},
volume = {13},
year = {2003}
}
@book{aitchison2011statistical,
author = {Aitchison, J},
doi = {9781930665781},
isbn = {9781930665781},
publisher = {Springer Netherlands},
series = {Monographs on Statistics and Applied Probability},
title = {{The Statistical Analysis of Compositional Data}},
url = {http://books.google.es/books?id=N1LOngEACAAJ},
year = {2011}
}
@article{Austin2004,
author = {Austin, Peter C and Tu, Jack V},
doi = {10.1198/0003130043277},
file = {:Users/marc/Library/Application Support/Mendeley Desktop/Downloaded/Austin, Tu - 2004 - Bootstrap Methods for Developing Predictive Models.pdf:pdf},
issn = {0003-1305},
journal = {The American Statistician},
month = may,
number = {2},
pages = {131--137},
title = {{Bootstrap Methods for Developing Predictive Models}},
volume = {58},
year = {2004}
}
@inbook{buccianti2011natural,
author = {Buccianti, Antonella},
booktitle = {Compositional Data Analysis},
doi = {10.1002/9781119976462.ch18},
isbn = {9781119976462},
keywords = {adding independent random variables - asymptotica,and uncertainty,central limit theorem,cycles of elements,from volcanic discharges,geochemical processes and log-r,governing distribution of elements in geochemistr,investigating geochemical behaviour - of elements,log-ratio approach and,natural laws,using log-ratios},
pages = {255--266},
publisher = {John Wiley \& Sons, Ltd},
title = {{Natural Laws Governing the Distribution of the Elements in Geochemistry: The Role of the Log-Ratio Approach}},
url = {http://dx.doi.org/10.1002/9781119976462.ch18},
year = {2011}
}
@inproceedings{monti2011shifted,
address = {Sant Feliu de Gu\'{\i}xols},
author = {Monti, Gianna Serafina and Mateu-Figueras, Gl\`{o}ria and Pawlowsky-Glahn, Vera and Egozcue, Juan Jos\'{e}},
booktitle = {CoDaWork 2011, the 4th International Workshop on Compositional Data Analysis},
editor = {Egozcue, J J and Tolosana-Delgado, R and Ortego, M I},
isbn = {978-84-87867-76-7},
keywords = {aitchison geometry,compositional data},
publisher = {CIMNE},
title = {{The shifted-scaled Dirichlet distribution in the simplex}},
url = {http://hdl.handle.net/10281/22158},
year = {2011}
}
@article{narayanan1991algorithm,
author = {Narayanan, A},
journal = {Applied Statistics},
pages = {365--374},
publisher = {JSTOR},
title = {{Algorithm AS 266: maximum likelihood estimation of the parameters of the Dirichlet distribution}},
year = {1991}
}
@article{VanMeurs2014,
abstract = {OBJECTIVE: Models to predict the probability of recurrence free survival exist for various types of malignancies, but a model for recurrence free survival in individuals with an adult granulosa cell tumor (GCT) of the ovary is lacking. We aimed to develop and internally validate such a prognostic model.

METHODS: We performed a multicenter retrospective cohort study of patients with a GCT. Demographic, clinical and pathological information were considered as potential predictors. Univariable and multivariable analyses were performed using a Cox proportional hazards model. Using backward stepwise selection we identified the combination of predictors that best predicted recurrence free survival. Discrimination (c-statistic) and calibration were used to assess model performance. The model was internally validated using bootstrapping techniques to correct for overfitting. To increase clinical applicability of the model we developed a nomogram to allow individual prediction of recurrence free survival.

RESULTS: We identified 127 patients with a GCT (median follow-up time was 131 months (IQR 70-215)). Recurrence of GCT occurred in 81 out of 127 patients (64\%). The following four variables jointly best predicted recurrence free survival; clinical stage, Body Mass Index (BMI), tumor diameter and mitotic index. The model had a c-statistic of 0.73 (95\% CI 0.66-0.80) and showed accurate calibration.

CONCLUSIONS: Recurrence free survival in patients with an adult GCT of the ovary can be accurately predicted by a combination of BMI, clinical stage, tumor diameter and mitotic index. The introduced nomogram could facilitate in counseling patients and may help to guide patients and caregivers in joint decisions on post-treatment surveillance.},
author = {van Meurs, Hannah S and Schuit, Ewoud and Horlings, Hugo M and van der Velden, Jacobus and van Driel, Willemien J and Mol, Ben Willem J and Kenter, Gemma G and Buist, Marrije R},
doi = {10.1016/j.ygyno.2014.06.021},
file = {:Users/marc/Library/Application Support/Mendeley Desktop/Downloaded/van Meurs et al. - 2014 - Development and internal validation of a prognostic model to predict recurrence free survival in patients with.pdf:pdf},
issn = {1095-6859},
journal = {Gynecologic oncology},
keywords = {Granulosa cell tumor,Nomogram,Ovarian cancer,Prognosis,Recurrence,granulosa cell tumor},
month = sep,
number = {3},
pages = {498--504},
pmid = {24983647},
publisher = {Elsevier Inc.},
title = {{Development and internal validation of a prognostic model to predict recurrence free survival in patients with adult granulosa cell tumors of the ovary.}},
volume = {134},
year = {2014}
}
@article{barcelo1999comment,
author = {Barcel\'{o}-Vidal, Carles and Mart\'{\i}n-Fern\'{a}ndez, Josep A. and Pawlowsky-Glahn, Vera},
doi = {10.1023/A:1007520124870},
isbn = {0882-8121},
journal = {Mathematical Geology},
number = {5},
pages = {581--585},
publisher = {Kluwer Academic Publishers-Plenum Publishers},
title = {{Comment on ``Singularity and Nonnormality in the Classification of Compositional Data'' by Bohling, G. C., Davis, J. C., Olea, R. A. and Harff, J.}},
url = {http://dx.doi.org/10.1023/A:1007520124870},
volume = {31},
year = {1999}
}
@inproceedings{Bodlaender2010,
abstract = {In this paper, we show that the following problem has a ker- nel of quadratic size: given is a tree T whose vertices have been assigned colors and a non-negative integer weight, and given is an integer k.In a recoloring, the color of some vertices is changed. We are looking for a recoloring such that each color class induces a subtree of T and such that the total weight of all recolored vertices is at most k. Our result gen- eralizes a result by Bodlaender et al. [3] who give quadratic size kernel for the case that all vertices have unit weight.},
author = {Bodlaender, Hans L. and Comas, Marc},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-642-11266-9\_18},
isbn = {3642050050},
issn = {03029743},
pages = {212--223},
title = {{A kernel for convex recoloring of weighted forests}},
volume = {5901 LNCS},
year = {2010}
}
@article{Garcia-Gil2014,
abstract = {BACKGROUND: Area-based measures of economic deprivation are seldom applied to large medical records databases to establish population-scale associations between deprivation and disease. OBJECTIVE: To study the association between deprivation and incidence of common cancer types in a Southern European region. METHODS: Retrospective ecological study using the SIDIAP (Information System for the Development of Research in Primary Care) database of longitudinal electronic medical records for a representative population of Catalonia (Spain) and the MEDEA index based on urban socioeconomic indicators in the Spanish census. Study outcomes were incident cervical, breast, colorectal, prostate, and lung cancer in 2009-2012. The completeness of SIDIAP cancer recording was evaluated through linkage of a geographic data subset to a hospital cancer registry. Associations between MEDEA quintiles and cancer incidence was evaluated using zero-inflated Poisson regression adjusted for sex, age, smoking, alcoholism, obesity, hypertension, and diabetes. RESULTS: SIDIAP sensitivity was 63\% to 92\% for the five cancers studied. There was direct association between deprivation and lung, colorectal, and cervical cancer: incidence rate ratios (IRR) 1.82 [1.64-2.01], IRR 1.60 [1.34-1.90], IRR 1.22 [1.07-1.38], respectively, comparing the most deprived to most affluent areas. In wealthy areas, prostate and breast cancers were more common: IRR 0.92 [0.80-1.00], IRR 0.91 [0.78-1.06]. Adjustment for confounders attenuated the association with lung cancer risk (fully adjusted IRR 1.16 [1.08-1.25]), reversed the direction of the association with colorectal cancer (IRR 0.90 [0.84-0.95]), and did not modify the associations with cervical (IRR 1.27 [1.11-1.45]), prostate (0.74 [0.69-0.80]), and breast (0.76 [0.71-0.81]) cancer. CONCLUSIONS: Deprivation is associated differently with the occurrence of various cancer types. These results provide evidence that MEDEA is a useful, area-based deprivation index for analyses of the SIDIAP database. This information will be useful to improve screening programs, cancer prevention and management strategies, to reach patients more effectively, particularly in deprived urban areas.},
author = {Garcia-Gil, Maria and Elorza, Josep-Maria and Banque, Marta and Comas-Cuf\'{\i}, Marc and Blanch, Jordi and Ramos, Rafel and M\'{e}ndez-Boo, Leonardo and Hermosilla, Eduardo and Bolibar, Bonaventura and Prieto-Alhambra, Daniel},
doi = {10.1371/journal.pone.0109706},
issn = {1932-6203},
journal = {PloS one},
month = jan,
number = {10},
pages = {e109706},
pmid = {25329578},
title = {{Linking of Primary Care Records to Census Data to Study the Association between Socioeconomic Status and Cancer Incidence in Southern Europe: A Nation-Wide Ecological Study.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/25329578},
volume = {9},
year = {2014}
}
@article{mardia2007protein,
abstract = {A fundamental problem in bioinformatics is to characterize the secondary structure of a protein, which has traditionally been carried out by examining a scatterplot (Ramachandran plot) of the conformational angles. We examine two natural bivariate von Mises distributions--referred to as Sine and Cosine models--which have five parameters and, for concentrated data, tend to a bivariate normal distribution. These are analyzed and their main properties derived. Conditions on the parameters are established which result in bimodal behavior for the joint density and the marginal distribution, and we note an interesting situation in which the joint density is bimodal but the marginal distributions are unimodal. We carry out comparisons of the two models, and it is seen that the Cosine model may be preferred. Mixture distributions of the Cosine model are fitted to two representative protein datasets using the expectation maximization algorithm, which results in an objective partition of the scatterplot into a number of components. Our results are consistent with empirical observations; new insights are discussed.},
author = {Mardia, Kanti V. and Taylor, Charles C. and Subramaniam, Ganesh K.},
doi = {10.1111/j.1541-0420.2006.00682.x},
issn = {0006341X},
journal = {Biometrics},
keywords = {Bivariate angular data,Bivariate circular mixture,Directional statistics,Distribution on torus,Myoglobin,Protein conformational angles,Ramachandran plots},
pmid = {17688502},
title = {{Protein bioinformatics and mixtures of bivariate von Mises distributions for angular data}},
volume = {63},
year = {2007}
}
@article{mateu2013normal,
abstract = {Phenomena with a constrained sample space appear frequently in practice. This is the case e.g. with strictly positive data and with compositional data, like percentages and the like. If the natural measure of difference is not the absolute one, it is possible to use simple algebraic properties to show that it is more convenient to work with a geometry that is not the usual Euclidean geometry in real space, and with a measure which is not the usual Lebesgue measure, leading to alternative models which better fit the phenomenon under study. The general approach is presented and illustrated both on the positive real line and on the D-part simplex.},
archivePrefix = {arXiv},
arxivId = {0802.2643},
author = {Mateu-Figueras, Gl\`{o}ria and Pawlowsky-Glahn, Vera and Egozcue, Juan Jos\'{e}},
eprint = {0802.2643},
journal = {SORT},
month = feb,
number = {1},
pages = {29--56},
title = {{The normal distribution in some constrained sample spaces}},
url = {http://arxiv.org/abs/0802.2643},
volume = {37},
year = {2013}
}
@article{BIMJ:BIMJ4710300705,
author = {Pincus, R},
doi = {10.1002/bimj.4710300705},
issn = {1521-4036},
journal = {Biometrical Journal},
number = {7},
pages = {794},
publisher = {WILEY-VCH Verlag},
title = {{Aitchison, J.: The Statistical Analysis of Compositional Data. Chapman and Hall, London - New York 1986, XII, 416 pp., £ 25,00}},
url = {http://dx.doi.org/10.1002/bimj.4710300705},
volume = {30},
year = {1988}
}
@article{scott1971clustering,
abstract = {The standard classification model with several normal populations is extended to the cluster analysis situation where little or no previous information about the population parameters is available. Some common clustering procedures are shown to be extensions of likelihood ratio methods of classification. The analysis suggests that the procedures may have a tendency to partition the sample into groups of about the same size. This suggestion is examined in an example.},
author = {Scott, A.J. and Symons, M.J.},
issn = {0006341X},
journal = {Biometrics},
pages = {387--397},
title = {{Clustering methods based on likelihood ratio criteria}},
volume = {27},
year = {1971}
}
@article{vives2014individual,
abstract = {The usual Hotel ling T-2 control chart is not appropriate for monitoring processes where the quality characteristic is a mixture. The composition of mixtures are vectors of positive elements that represent parts of a whole, to which standard multivariate techniques are not appropriate due to their restricted sample space. There are many applications where a mixture is monitored against time, such as in the chemical industry, product composition, impurity profile, or gas components analysis. In this paper, a multivariate control chart for individual compositional observations based on the T-2 statistic is proposed and compared with the typical one in terms of average run length. We show how results are more consistent with compositional data nature and illustrate implementation in a real-world example.},
address = {600 N PLANKINTON AVE, MILWAUKEE, WI 53203 USA},
author = {Vives-Mestres, Marina and Daunis-i-Estadella, Josep and M\'{a}rtin-Fern\'{a}ndez, Josep A.},
issn = {0022-4065},
journal = {Journal of Quality Technology},
keywords = {Average Run Length,Hotelling's T-2 Statistic,Log Ratio,Mixture Data,Multivariate Control Chart,Simplex,Statistical Process Control},
number = {2},
pages = {127--139},
publisher = {AMER SOC QUALITY CONTROL-ASQC},
title = {{Individual T-2 Control Chart for Compositional Data}},
type = {Article},
volume = {46},
year = {2014}
}
@article{Zhang2014,
abstract = {Joint models for longitudinal and survival data now have a long history of being used in clinical trials or other studies in which the goal is to assess a treatment effect while accounting for longitudinal assessments such as patient-reported outcomes or tumor response. Compared to using survival data alone, the joint modeling of survival and longitudinal data allows for estimation of direct and indirect treatment effects, thereby resulting in improved efficacy assessment. Although global fit indices such as AIC or BIC can be used to rank joint models, these measures do not provide separate assessments of each component of the joint model. In this paper, we develop a novel decomposition of AIC and BIC (i.e., AIC = AICLong + AICSurv|Long and BIC = BICLong + BICSurv|Long ) that allows us to assess the fit of each component of the joint model and in particular to assess the fit of the longitudinal component of the model and the survival component separately. Based on this decomposition, we then propose $\Delta$AICSurv and $\Delta$BICSurv to determine the importance and contribution of the longitudinal data to the model fit of the survival data. Moreover, this decomposition, along with $\Delta$AICSurv and $\Delta$BICSurv , is also quite useful in comparing, for example, trajectory-based joint models and shared parameter joint models and deciding which type of model best fits the survival data. We examine a detailed case study in mesothelioma to apply our proposed methodology along with an extensive set of simulation studies. Copyright © 2014 John Wiley \& Sons, Ltd.},
author = {Zhang, Danjie and Chen, Ming-Hui and Ibrahim, Joseph G and Boye, Mark E and Wang, Ping and Shen, Wei},
doi = {10.1002/sim.6269},
file = {:Users/marc/Library/Application Support/Mendeley Desktop/Downloaded/Zhang et al. - 2014 - Assessing model fit in joint models of longitudinal and survival data with applications to cancer clinical trials.pdf:pdf},
issn = {1097-0258},
journal = {Statistics in medicine},
keywords = {10.1002/sim.6269 and AIC,BIC,Patient-reported outcome (PRO),Shared parameter model,Time-varying covariates model,Trajectory model.,aic,bic,model,patient-reported outcome,pro,shared parameter model,time-varying covariates,trajectory model},
month = nov,
number = {27},
pages = {4715--33},
pmid = {25044061},
title = {{Assessing model fit in joint models of longitudinal and survival data with applications to cancer clinical trials.}},
volume = {33},
year = {2014}
}
@article{andrews2012model,
abstract = {The last decade has seen an explosion of work on the use of mixture models for clustering. The use of the Gaussian mixture model has been common practice, with constraints sometimes imposed upon the component covariance matrices to give families of mixture models. Similar approaches have also been applied, albeit with less fecundity, to classification and discriminant analysis. In this paper, we begin with an introduction to model-based clustering and a succinct account of the state-of-the-art. We then put forth a novel family of mixture models wherein each component is modeled using a multivariate t -distribution with an eigen-decomposed covariance structure. This family, which is largely a t -analogue of the well-known MCLUST family, is known as the t EIGEN family. The efficacy of this family for clustering, classification, and discriminant analysis is illustrated with both real and simulated data. The performance of this family is compared to its Gaussian counterpart on three real data sets.},
author = {Andrews, Jeffrey L. and McNicholas, Paul D.},
doi = {10.1007/s11222-011-9272-x},
isbn = {1122201192},
issn = {09603174},
journal = {Statistics and Computing},
keywords = {Classification,Clustering,Discriminant analysis,Eigen-decomposition,Mixture models,Model-based clustering,Multivariate t-distribution},
pages = {1021--1029},
title = {{Model-based clustering, classification, and discriminant analysis via mixtures of multivariate t-distributions: The tEIGEN family}},
volume = {22},
year = {2012}
}
@article{azzalini1999statistical,
author = {Azzalini, Adelchi and Capitanio, Antonella},
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
number = {3},
pages = {579--602},
publisher = {Wiley Online Library},
title = {{Statistical applications of the multivariate skew normal distribution}},
volume = {61},
year = {1999}
}
@article{Comas2007,
abstract = {Given a graph G = (V, E), a positive integer k, and a positive integer d, we want find a subset V k with k vertices such the graph obtained by identifying the vertices from V k in G has diameter at most d. We prove that for every d ??? 2 the problem is NP-complete. For the case of trees we provide a polynomial time algorithm that exploits the relationship with the r-dominating set problem. ?? 2007 Elsevier B.V. All rights reserved.},
author = {Comas, Marc and Serna, Maria},
journal = {Electronic Notes in Discrete Mathematics},
keywords = {Augmentation problems,graph diameter,r-dominating set},
number = {SPEC. ISS.},
pages = {261--265},
title = {{Vertex fusion under diameter constraints}},
volume = {29},
year = {2007}
}
@article{lee2013finite,
address = {Hingham, MA, USA},
author = {Lee, Sharon X. and McLachlan, Geoffrey J.},
doi = {10.1007/s11222-012-9362-4},
issn = {0960-3174},
journal = {Statistics and Computing},
keywords = {EM algorithm,Mixture models,Skew normal distributions,Skew t component distributions},
number = {2},
pages = {181--202},
publisher = {Kluwer Academic Publishers},
title = {{Finite mixtures of multivariate skew t-distributions: some recent and new results}},
url = {http://dx.doi.org/10.1007/s11222-012-9362-4},
volume = {24},
year = {2014}
}
@book{ng2011dirichlet,
author = {Ng, Kai Wang and Tian, Guo-Liang and Tang, Man-Lai},
publisher = {John Wiley \& Sons},
title = {{Dirichlet and Related Distributions: Theory, Methods and Applications}},
volume = {888},
year = {2011}
}
@article{Steyerberg2001,
author = {Steyerberg, Ewout W and Harrell, Frank E and Borsboom, Gerard J J M and Eijkemans, M J C Ren\'{e} and Vergouwe, Yvonne and Habbema, J Dik F},
file = {:Users/marc/Library/Application Support/Mendeley Desktop/Downloaded/Steyerberg et al. - 2001 - Internal validation of predictive models Efficiency of some procedures for logistic regression analysis.pdf:pdf},
keywords = {bootstrapping,internal validation,logistic regression analysis,predictive models},
pages = {774--781},
title = {{Internal validation of predictive models : Efficiency of some procedures for logistic regression analysis}},
volume = {54},
year = {2001}
}
@inproceedings{tantrum2003assessment,
address = {New York, NY, USA},
author = {Tantrum, Jeremy and Murua, Alejandro and Stuetzle, Werner},
booktitle = {Proceedings of the Ninth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
doi = {10.1145/956750.956775},
file = {:Users/marc/Library/Application Support/Mendeley Desktop/Downloaded/Tantrum, Murua, Stuetzle - 2003 - Assessment and Pruning of Hierarchical Model Based Clustering.pdf:pdf},
isbn = {1-58113-737-0},
keywords = {density estimation,model-based clustering,nonparametric clustering,unimodality},
pages = {197--205},
publisher = {ACM},
series = {KDD '03},
title = {{Assessment and Pruning of Hierarchical Model Based Clustering}},
url = {http://doi.acm.org/10.1145/956750.956775},
year = {2003}
}
@inproceedings{,
booktitle = {The 4th international Workshop on Compositional Data Analysis},
title = {{CoDaWork 2011}},
year = {2011}
}
